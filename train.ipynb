{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "- EDA를 진행하면서 동시에 csv를 만들었습니다.\n",
    "- image와 label을 반환합니다.\n",
    "- albumentations augmentation을 염두해두고 설계했기 때문에 이미지를 opencv로 읽었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtPaintDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index()\n",
    "        self.image_id = self.df.image_id\n",
    "        self.labels = self.df.label\n",
    "        self.transform = transform        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def set_transform(self, transform):        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_id[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "\n",
    "        return {'image' : image, 'label' : label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import timm\n",
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from madgrad import MADGRAD\n",
    "from adamp import AdamP\n",
    "from easydict import EasyDict\n",
    "from prettyprinter import cpprint\n",
    "from torchsummary import summary as summary_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConfigManager\n",
    "- .yaml 파일을 사용하여 config를 관리했습니다.\n",
    "- config를 바꿔가며 실험했습니다.\n",
    "- 최종적으로 사용한 config는 다음과 같습니다.\n",
    "---\n",
    "```\n",
    "base:\n",
    "  seed: 77\n",
    "  model_arc: 'nfnet_l0'\n",
    "  num_classes: 7\n",
    "  input_dir: './train/train.csv'\n",
    "  output_dir: './results/'\n",
    "  train_only: False\n",
    "  image_size: 227\n",
    "  cutmix_args:\n",
    "    use_cutmix: False\n",
    "    beta: 1.0\n",
    "    cutmix_prob: 0.5\n",
    "  train_args:\n",
    "    num_epochs: 6\n",
    "    train_batch_size: 32\n",
    "    val_batch_size: 32\n",
    "    max_lr: 0.0001\n",
    "    min_lr: 0.00001\n",
    "    cycle: 3\n",
    "    gamma: 0.5\n",
    "    weight_decay: 0.000001\n",
    "    log_intervals: 10\n",
    "    eval_metric: 'accuracy'    \n",
    "    n_splits: 5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "swin:\n",
    "  seed: 777\n",
    "  model_arc: 'swin_base_patch4_window7_224'\n",
    "  num_classes: 7\n",
    "  input_dir: './train/train.csv'\n",
    "  output_dir: './results/'\n",
    "  train_only: False\n",
    "  image_size: 224\n",
    "  cutmix_args:\n",
    "    use_cutmix: True\n",
    "    beta: 1.0\n",
    "    cutmix_prob: 0.5\n",
    "  train_args:\n",
    "    num_epochs: 10\n",
    "    train_batch_size: 16\n",
    "    val_batch_size: 16\n",
    "    max_lr: 0.0001\n",
    "    min_lr: 0.00001\n",
    "    cycle: 3\n",
    "    gamma: 0.5\n",
    "    weight_decay: 0.000001\n",
    "    log_intervals: 10\n",
    "    eval_metric: 'accuracy'    \n",
    "    n_splits: 5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Config\n",
    "class YamlConfigManager:\n",
    "    def __init__(self, config_file_path='./config.yml', config_name='xception'):\n",
    "        super().__init__()\n",
    "        self.values = EasyDict()        \n",
    "        if config_file_path:\n",
    "            self.config_file_path = config_file_path\n",
    "            self.config_name = config_name\n",
    "            self.reload()\n",
    "    \n",
    "    def reload(self):\n",
    "        self.clear()\n",
    "        if self.config_file_path:\n",
    "            with open(self.config_file_path, 'r') as f:\n",
    "                self.values.update(yaml.safe_load(f)[self.config_name])\n",
    "\n",
    "    def clear(self):\n",
    "        self.values.clear()\n",
    "    \n",
    "    def update(self, yml_dict):\n",
    "        for (k1, v1) in yml_dict.items():\n",
    "            if isinstance(v1, dict):\n",
    "                for (k2, v2) in v1.items():\n",
    "                    if isinstance(v2, dict):\n",
    "                        for (k3, v3) in v2.items():\n",
    "                            self.values[k1][k2][k3] = v3\n",
    "                    else:\n",
    "                        self.values[k1][k2] = v2\n",
    "            else:\n",
    "                self.values[k1] = v1\n",
    "\n",
    "    def export(self, save_file_path):\n",
    "        if save_file_path:\n",
    "            with open(save_file_path, 'w') as f:\n",
    "                yaml.dump(dict(self.values), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = YamlConfigManager()\n",
    "\n",
    "SEED = cfg.values.seed\n",
    "INPUT_DIR = cfg.values.input_dir\n",
    "TRAIN_ONLY = cfg.values.train_only\n",
    "IMAGE_SIZE = cfg.values.image_size\n",
    "TRAIN_BATCH_SIZE = cfg.values.train_args.train_batch_size\n",
    "VAL_BATCH_SIZE = cfg.values.train_args.val_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEED 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- 만들어둔 csv 파일을 불러왔습니다.\n",
    "\n",
    "### Augmentation\n",
    "- HorizontalFlip() : TTA를 염두해두고 선택하였습니다.\n",
    "- ToGray() : 그림 이미지라서 색조가 너무 다양할 것이라고 생각하여 gray scale에서도 feature를 잡을 수 있었으면 했습니다.\n",
    "- Blur() : 그림 이미지 특성상 blurring된 효과가 많이 있을 것이라 생각하여 채택했습니다.\n",
    "- Normalize RGB mean, std 값은 eda.ipynb를 통해 직접 계산했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1621735577479,
     "user": {
      "displayName": "김효진",
      "photoUrl": "",
      "userId": "06712056052855259710"
     },
     "user_tz": -540
    },
    "id": "9MajXDBf-BRL",
    "outputId": "a8f46576-f639-448c-bddf-ce18c30ca06b"
   },
   "outputs": [],
   "source": [
    "# # Caculate mean and std\n",
    "\n",
    "# # pixel count\n",
    "# count = len(train_df) * 227 * 227\n",
    "\n",
    "# # mean and std\n",
    "# total_mean = psum / count\n",
    "# total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "# total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# # output\n",
    "# print('mean: '  + str(total_mean))\n",
    "# print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_csv(INPUT_DIR)\n",
    "whole_label = whole_df['label'].values\n",
    "\n",
    "train_transform = albumentations.Compose([\n",
    "    albumentations.OneOf([\n",
    "        albumentations.HorizontalFlip(),\n",
    "        albumentations.ToGray(),\n",
    "        albumentations.Blur()\n",
    "    ]), \n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albumentations.Normalize(mean=(0.4569, 0.5074, 0.5557), std=(0.2888, 0.2743, 0.2829)),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "val_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albumentations.Normalize(mean=(0.4569, 0.5074, 0.5557), std=(0.2888, 0.2743, 0.2829)),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- timm library를 사용했습니다.\n",
    "- NFNet, EfficientNet\n",
    "    - kaggle ailen signal search 대회에 참가 중인데 nfnet과 efficientnet이 대체로 성능이 좋았습니다.\n",
    "    - 첫 제출 당시에 NFNet을 사용했는데 1.0이 나와서 놀랐습니다. \n",
    "    - 문제가 쉬운 대회인 만큼 shake up이 심할거라 생각해서 다른 모델들도 테스트했지만 val score가 좋지 않았습니다.\n",
    "    - LB score\n",
    "        - efficientnet_b0 : `90.0`\n",
    "        - nfnet_l0 : `100.0`\n",
    "- Swin-transformer\n",
    "    - naver boostcamp에서 competition 진행했었는데 detection 대회에서 swin-transformer를 사용해서 2등을 했습니다.\n",
    "    - 당시에 성능이 좋았습니다.\n",
    "    - 구조가 다른 모델끼리 앙상블할 경우에 generalized performance가 올라갈 것이라고 생각했습니다. \n",
    "    - LB score\n",
    "        - swin-base-224-22k : `97.14`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, model_arc='resnet18d', num_classes=7):\n",
    "        super().__init__()\n",
    "        self.net = timm.create_model(model_arc, pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils\n",
    "- 여러가지 유틸 함수들을 정의했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(df, transform, batch_size, shuffle):\n",
    "    dataset = ArtPaintDataset(df=df, transform=transform)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CosineAnnealingWarmupRestarts\n",
    "- gamma 비율로 감소하는 cosine annealing warmup restart scheduler가 lr 분석하기 제일 편했습니다.\n",
    "- 경험에 의해서 선택했으며, wandb와 함께 사용할 경우 optimizer 분석에 매우 용이했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    \"\"\"\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        first_cycle_steps (int): First cycle step size.\n",
    "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
    "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
    "        min_lr(float): Min learning rate. Default: 0.001.\n",
    "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
    "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 optimizer : torch.optim.Optimizer,\n",
    "                 first_cycle_steps : int,\n",
    "                 cycle_mult : float = 1.,\n",
    "                 max_lr : float = 0.1,\n",
    "                 min_lr : float = 0.001,\n",
    "                 warmup_steps : int = 0,\n",
    "                 gamma : float = 1.,\n",
    "                 last_epoch : int = -1\n",
    "        ):\n",
    "        assert warmup_steps < first_cycle_steps\n",
    "        \n",
    "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
    "        self.base_max_lr = max_lr # first max learning rate\n",
    "        self.max_lr = max_lr # max learning rate in the current cycle\n",
    "        self.min_lr = min_lr # min learning rate\n",
    "        self.warmup_steps = warmup_steps # warmup step size\n",
    "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
    "        \n",
    "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle = 0 # cycle count\n",
    "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
    "        \n",
    "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "        # set learning rate min_lr\n",
    "        self.init_lr()\n",
    "    \n",
    "    def init_lr(self):\n",
    "        self.base_lrs = []\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.min_lr\n",
    "            self.base_lrs.append(self.min_lr)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.step_in_cycle == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.step_in_cycle < self.warmup_steps:\n",
    "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.max_lr - base_lr) \\\n",
    "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
    "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.step_in_cycle = self.step_in_cycle + 1\n",
    "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
    "                self.cycle += 1\n",
    "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
    "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
    "        else:\n",
    "            if epoch >= self.first_cycle_steps:\n",
    "                if self.cycle_mult == 1.:\n",
    "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
    "                    self.cycle = epoch // self.first_cycle_steps\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
    "                    self.cycle = n\n",
    "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
    "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
    "            else:\n",
    "                self.cur_cycle_steps = self.first_cycle_steps\n",
    "                self.step_in_cycle = epoch\n",
    "                \n",
    "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CutMix\n",
    "- Robust한 모델을 만들기 위해 선택한 방법입니다.\n",
    "- 쉬운 문제에서 사용할 경우 성능이 많이 좋아졌었던 경험이 있습니다.\n",
    "- 학습을 더욱 복잡하게 만들어서 generalized performance의 향상을 노렸습니다.\n",
    "- NFNet에서는 사용하지 않았고, Swin Transformer에만 사용해서 앙상블했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    width = size[2]\n",
    "    height = size[3]\n",
    "    cut_ratio = np.sqrt(1. - lam)\n",
    "    cut_width = np.int(width * cut_ratio)\n",
    "    cut_height = np.int(height * cut_ratio)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(width)\n",
    "    cy = np.random.randint(height)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_width // 2, 0, width)\n",
    "    bby1 = np.clip(cy - cut_height // 2, 0, height)\n",
    "    bbx2 = np.clip(cx + cut_width // 2, 0, width)\n",
    "    bby2 = np.clip(cy + cut_height // 2, 0, height)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutMix(object):\n",
    "    def __init__(self, beta, cutmix_prob) -> None:\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.cutmix_prob = cutmix_prob \n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        # generate mixed sample\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        rand_index = torch.randperm(images.size()[0]).cuda()\n",
    "        label_1 = labels\n",
    "        label_2 = labels[rand_index]\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "        images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # adjust lambda to exactly match pixel ratio\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
    "\n",
    "        return {'lam' : lam, 'image' : images, 'label_1' : label_1, 'label_2' : label_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMetric(object):\n",
    "    def __init__(self, metric) -> None:\n",
    "        super().__init__() \n",
    "        self.metric = metric    \n",
    "\n",
    "    def cutmix_accuracy(self, logits, labels, topk=(1, 5)):\n",
    "        max_k = max(topk)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        _, pred = logits.topk(max_k, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        matches = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            matches_k = matches[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            wrong_k = batch_size - matches_k\n",
    "            res.append(matches_k.mul_(100.0 / batch_size))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def compute(self, logits, labels, topk=(1, 5)):\n",
    "        if self.metric == 'accuracy':\n",
    "            out = self.cutmix_accuracy(logits=logits, labels=labels, topk=topk)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지표 계산을 위한 average meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    " - 5 Fold cross validation 사용\n",
    " - 모델 별로 lr, epoch 조절해가면서 다르게 학습했습니다.\n",
    " - EDA(eda.ipynb 파일 만들어서 진행) 해봤을 때 guitar와 person같이 class imbalance가 있어 stratified하게 train과 validation 분할 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as pyplot\n",
    "# import seaborn as sns\n",
    "\n",
    "# ax = sns.countplot(train_df['label'])\n",
    "\n",
    "# for p, label in zip(ax.patches, label_list):\n",
    "#     ax.annotate(label, (p.get_x(), p.get_height() + 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, k, train_loader, val_loader):\n",
    "    # Set Config\n",
    "    MODEL_ARC = cfg.values.model_arc\n",
    "    OUTPUT_DIR = cfg.values.output_dir\n",
    "    NUM_CLASSES = cfg.values.num_classes\n",
    "    TRAIN_ONLY = cfg.values.train_only\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Set train arguments\n",
    "    num_epochs = cfg.values.train_args.num_epochs\n",
    "    train_batch_size = cfg.values.train_args.train_batch_size\n",
    "    log_intervals = cfg.values.train_args.log_intervals\n",
    "    max_lr = cfg.values.train_args.max_lr\n",
    "    min_lr = cfg.values.train_args.min_lr\n",
    "    cycle = cfg.values.train_args.cycle\n",
    "    gamma = cfg.values.train_args.gamma\n",
    "\n",
    "    # Set CutMix arguments\n",
    "    USE_CUTMIX = cfg.values.cutmix_args.use_cutmix    \n",
    "    beta = cfg.values.cutmix_args.beta\n",
    "    cutmix_prob = cfg.values.cutmix_args.cutmix_prob    \n",
    "    cutmix = CutMix(beta=beta, cutmix_prob=cutmix_prob)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = PretrainedModel(model_arc=MODEL_ARC, num_classes=NUM_CLASSES)\n",
    "    model.to(device)\n",
    "    if k < 2:\n",
    "        summary_(model, (3, IMAGE_SIZE, IMAGE_SIZE), batch_size=train_batch_size)\n",
    "\n",
    "    optimizer = MADGRAD(model.parameters(), lr=max_lr, weight_decay=cfg.values.train_args.weight_decay)\n",
    "    first_cycle_steps = len(train_loader) * num_epochs // cycle\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer, \n",
    "        first_cycle_steps=first_cycle_steps, \n",
    "        cycle_mult=1.0,\n",
    "        max_lr=max_lr, \n",
    "        min_lr=min_lr, \n",
    "        warmup_steps=int(first_cycle_steps * 0.2), \n",
    "        gamma=gamma\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    eval_metric = ComputeMetric(cfg.values.train_args.eval_metric)\n",
    "    best_acc = 0.\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, MODEL_ARC), exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_values = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "\n",
    "        for i, train_batch in enumerate(tqdm(train_loader, desc=f'Training')):\n",
    "            sample = train_batch\n",
    "            images = sample['image'].float().to(device)\n",
    "            labels = sample['label'].long().to(device)\n",
    "\n",
    "            ratio = np.random.rand(1)\n",
    "\n",
    "            if USE_CUTMIX:\n",
    "                if beta > 0 and ratio < cutmix_prob:\n",
    "                    # generate mixed sample\n",
    "                    sample = cutmix.forward(images, labels)\n",
    "\n",
    "                    logits = model(sample['image'])                    \n",
    "                    loss = criterion(logits, sample['label_1']) * sample['lam'] + criterion(logits, sample['label_2']) * (1. - sample['lam'])\n",
    "                else:\n",
    "                    logits = model(images)\n",
    "                    loss = criterion(logits, labels)\n",
    "            else:\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            # measure evaluation metric and record loss\n",
    "            top1_err, top5_err = eval_metric.compute(logits.data, labels, topk=(1, 5))\n",
    "\n",
    "            loss_values.update(loss.item(), images.size(0))\n",
    "            top1.update(top1_err.item(), images.size(0))\n",
    "            top5.update(top5_err.item(), images.size(0))\n",
    "\n",
    "            # compute gradient and do optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if i % log_intervals == 0:\n",
    "                current_lr = scheduler.get_lr()[0]\n",
    "                tqdm.write(f'Epoch : [{epoch + 1}/{num_epochs}][{i}/{len(train_loader)}] || '\n",
    "                           f'LR : {current_lr:.5f} || '\n",
    "                           f'Train Loss : {loss_values.val:.4f} ({loss_values.avg:.4f}) || '                        \n",
    "                           f'Train Top 1-acc : {top1.val:.3f}% ({top1.avg:.3f})% || '\n",
    "                           f'Train Top 5-acc : {top5.val:.3f}% ({top5.avg:.3f})%')\n",
    "\n",
    "        loss_values = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "        \n",
    "        if not TRAIN_ONLY:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                loss_values = AverageMeter()\n",
    "                top1 = AverageMeter()\n",
    "                top5 = AverageMeter()\n",
    "\n",
    "                for i, val_batch in enumerate(tqdm(val_loader, desc=f'Validation')):\n",
    "                    sample = val_batch\n",
    "                    images = sample['image'].float().to(device)\n",
    "                    labels = sample['label'].long().to(device)\n",
    "\n",
    "                    logits = model(images)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    preds = torch.argmax(logits, -1)\n",
    "\n",
    "                    top1_err, top5_err = eval_metric.compute(logits.data, labels, topk=(1, 5))\n",
    "                    loss_values.update(loss.item(), images.size(0))\n",
    "                    top1.update(top1_err.item(), images.size(0))\n",
    "                    top5.update(top5_err.item(), images.size(0))\n",
    "\n",
    "            tqdm.write(f'Epoch : [{epoch + 1}/{num_epochs}] || '\n",
    "                       f'Val Loss : {loss_values.avg:.4f} || '                        \n",
    "                       f'Val Top 1-acc : {top1.avg:.3f}% || '\n",
    "                       f'Val Top 5-acc : {top5.avg:.3f}%')\n",
    "\n",
    "            is_best = top1.avg >= best_acc\n",
    "            best_acc = max(top1.avg, best_acc)\n",
    "\n",
    "            if is_best:\n",
    "                if k > 0:\n",
    "                    os.makedirs(os.path.join(OUTPUT_DIR, MODEL_ARC, f'{k}_fold'), exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, MODEL_ARC, f'{k}_fold', f'{epoch + 1}_epoch_{best_acc:.2f}%_with_val.pth'))\n",
    "                else:                    \n",
    "                    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, MODEL_ARC, f'{epoch + 1}_epoch_{best_acc:.2f}%_with_val.pth'))\n",
    "        \n",
    "        else:\n",
    "            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, MODEL_ARC, f'_{epoch + 1}_epoch_{top1.avg:.2f}%_only_train.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "'===============1-Fold Cross Validation==============='\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 32, 113, 113]             864\n",
      "       BatchNorm2d-2         [32, 32, 113, 113]              64\n",
      "              ReLU-3         [32, 32, 113, 113]               0\n",
      "            Conv2d-4         [32, 64, 111, 111]          18,432\n",
      "       BatchNorm2d-5         [32, 64, 111, 111]             128\n",
      "              ReLU-6         [32, 64, 111, 111]               0\n",
      "            Conv2d-7         [32, 64, 111, 111]             576\n",
      "            Conv2d-8        [32, 128, 111, 111]           8,192\n",
      "   SeparableConv2d-9        [32, 128, 111, 111]               0\n",
      "      BatchNorm2d-10        [32, 128, 111, 111]             256\n",
      "             ReLU-11        [32, 128, 111, 111]               0\n",
      "           Conv2d-12        [32, 128, 111, 111]           1,152\n",
      "           Conv2d-13        [32, 128, 111, 111]          16,384\n",
      "  SeparableConv2d-14        [32, 128, 111, 111]               0\n",
      "      BatchNorm2d-15        [32, 128, 111, 111]             256\n",
      "        MaxPool2d-16          [32, 128, 56, 56]               0\n",
      "           Conv2d-17          [32, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-18          [32, 128, 56, 56]             256\n",
      "            Block-19          [32, 128, 56, 56]               0\n",
      "             ReLU-20          [32, 128, 56, 56]               0\n",
      "           Conv2d-21          [32, 128, 56, 56]           1,152\n",
      "           Conv2d-22          [32, 256, 56, 56]          32,768\n",
      "  SeparableConv2d-23          [32, 256, 56, 56]               0\n",
      "      BatchNorm2d-24          [32, 256, 56, 56]             512\n",
      "             ReLU-25          [32, 256, 56, 56]               0\n",
      "           Conv2d-26          [32, 256, 56, 56]           2,304\n",
      "           Conv2d-27          [32, 256, 56, 56]          65,536\n",
      "  SeparableConv2d-28          [32, 256, 56, 56]               0\n",
      "      BatchNorm2d-29          [32, 256, 56, 56]             512\n",
      "        MaxPool2d-30          [32, 256, 28, 28]               0\n",
      "           Conv2d-31          [32, 256, 28, 28]          32,768\n",
      "      BatchNorm2d-32          [32, 256, 28, 28]             512\n",
      "            Block-33          [32, 256, 28, 28]               0\n",
      "             ReLU-34          [32, 256, 28, 28]               0\n",
      "           Conv2d-35          [32, 256, 28, 28]           2,304\n",
      "           Conv2d-36          [32, 728, 28, 28]         186,368\n",
      "  SeparableConv2d-37          [32, 728, 28, 28]               0\n",
      "      BatchNorm2d-38          [32, 728, 28, 28]           1,456\n",
      "             ReLU-39          [32, 728, 28, 28]               0\n",
      "           Conv2d-40          [32, 728, 28, 28]           6,552\n",
      "           Conv2d-41          [32, 728, 28, 28]         529,984\n",
      "  SeparableConv2d-42          [32, 728, 28, 28]               0\n",
      "      BatchNorm2d-43          [32, 728, 28, 28]           1,456\n",
      "        MaxPool2d-44          [32, 728, 14, 14]               0\n",
      "           Conv2d-45          [32, 728, 14, 14]         186,368\n",
      "      BatchNorm2d-46          [32, 728, 14, 14]           1,456\n",
      "            Block-47          [32, 728, 14, 14]               0\n",
      "             ReLU-48          [32, 728, 14, 14]               0\n",
      "           Conv2d-49          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-50          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-51          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-52          [32, 728, 14, 14]           1,456\n",
      "             ReLU-53          [32, 728, 14, 14]               0\n",
      "           Conv2d-54          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-55          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-56          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-57          [32, 728, 14, 14]           1,456\n",
      "             ReLU-58          [32, 728, 14, 14]               0\n",
      "           Conv2d-59          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-60          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-61          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-62          [32, 728, 14, 14]           1,456\n",
      "            Block-63          [32, 728, 14, 14]               0\n",
      "             ReLU-64          [32, 728, 14, 14]               0\n",
      "           Conv2d-65          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-66          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-67          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-68          [32, 728, 14, 14]           1,456\n",
      "             ReLU-69          [32, 728, 14, 14]               0\n",
      "           Conv2d-70          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-71          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-72          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-73          [32, 728, 14, 14]           1,456\n",
      "             ReLU-74          [32, 728, 14, 14]               0\n",
      "           Conv2d-75          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-76          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-77          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-78          [32, 728, 14, 14]           1,456\n",
      "            Block-79          [32, 728, 14, 14]               0\n",
      "             ReLU-80          [32, 728, 14, 14]               0\n",
      "           Conv2d-81          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-82          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-83          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-84          [32, 728, 14, 14]           1,456\n",
      "             ReLU-85          [32, 728, 14, 14]               0\n",
      "           Conv2d-86          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-87          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-88          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-89          [32, 728, 14, 14]           1,456\n",
      "             ReLU-90          [32, 728, 14, 14]               0\n",
      "           Conv2d-91          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-92          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-93          [32, 728, 14, 14]               0\n",
      "      BatchNorm2d-94          [32, 728, 14, 14]           1,456\n",
      "            Block-95          [32, 728, 14, 14]               0\n",
      "             ReLU-96          [32, 728, 14, 14]               0\n",
      "           Conv2d-97          [32, 728, 14, 14]           6,552\n",
      "           Conv2d-98          [32, 728, 14, 14]         529,984\n",
      "  SeparableConv2d-99          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-100          [32, 728, 14, 14]           1,456\n",
      "            ReLU-101          [32, 728, 14, 14]               0\n",
      "          Conv2d-102          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-103          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-104          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-105          [32, 728, 14, 14]           1,456\n",
      "            ReLU-106          [32, 728, 14, 14]               0\n",
      "          Conv2d-107          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-108          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-109          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-110          [32, 728, 14, 14]           1,456\n",
      "           Block-111          [32, 728, 14, 14]               0\n",
      "            ReLU-112          [32, 728, 14, 14]               0\n",
      "          Conv2d-113          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-114          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-115          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-116          [32, 728, 14, 14]           1,456\n",
      "            ReLU-117          [32, 728, 14, 14]               0\n",
      "          Conv2d-118          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-119          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-120          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-121          [32, 728, 14, 14]           1,456\n",
      "            ReLU-122          [32, 728, 14, 14]               0\n",
      "          Conv2d-123          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-124          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-125          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-126          [32, 728, 14, 14]           1,456\n",
      "           Block-127          [32, 728, 14, 14]               0\n",
      "            ReLU-128          [32, 728, 14, 14]               0\n",
      "          Conv2d-129          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-130          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-131          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-132          [32, 728, 14, 14]           1,456\n",
      "            ReLU-133          [32, 728, 14, 14]               0\n",
      "          Conv2d-134          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-135          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-136          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-137          [32, 728, 14, 14]           1,456\n",
      "            ReLU-138          [32, 728, 14, 14]               0\n",
      "          Conv2d-139          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-140          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-141          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-142          [32, 728, 14, 14]           1,456\n",
      "           Block-143          [32, 728, 14, 14]               0\n",
      "            ReLU-144          [32, 728, 14, 14]               0\n",
      "          Conv2d-145          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-146          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-147          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-148          [32, 728, 14, 14]           1,456\n",
      "            ReLU-149          [32, 728, 14, 14]               0\n",
      "          Conv2d-150          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-151          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-152          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-153          [32, 728, 14, 14]           1,456\n",
      "            ReLU-154          [32, 728, 14, 14]               0\n",
      "          Conv2d-155          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-156          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-157          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-158          [32, 728, 14, 14]           1,456\n",
      "           Block-159          [32, 728, 14, 14]               0\n",
      "            ReLU-160          [32, 728, 14, 14]               0\n",
      "          Conv2d-161          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-162          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-163          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-164          [32, 728, 14, 14]           1,456\n",
      "            ReLU-165          [32, 728, 14, 14]               0\n",
      "          Conv2d-166          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-167          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-168          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-169          [32, 728, 14, 14]           1,456\n",
      "            ReLU-170          [32, 728, 14, 14]               0\n",
      "          Conv2d-171          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-172          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-173          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-174          [32, 728, 14, 14]           1,456\n",
      "           Block-175          [32, 728, 14, 14]               0\n",
      "            ReLU-176          [32, 728, 14, 14]               0\n",
      "          Conv2d-177          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-178          [32, 728, 14, 14]         529,984\n",
      " SeparableConv2d-179          [32, 728, 14, 14]               0\n",
      "     BatchNorm2d-180          [32, 728, 14, 14]           1,456\n",
      "            ReLU-181          [32, 728, 14, 14]               0\n",
      "          Conv2d-182          [32, 728, 14, 14]           6,552\n",
      "          Conv2d-183         [32, 1024, 14, 14]         745,472\n",
      " SeparableConv2d-184         [32, 1024, 14, 14]               0\n",
      "     BatchNorm2d-185         [32, 1024, 14, 14]           2,048\n",
      "       MaxPool2d-186           [32, 1024, 7, 7]               0\n",
      "          Conv2d-187           [32, 1024, 7, 7]         745,472\n",
      "     BatchNorm2d-188           [32, 1024, 7, 7]           2,048\n",
      "           Block-189           [32, 1024, 7, 7]               0\n",
      "          Conv2d-190           [32, 1024, 7, 7]           9,216\n",
      "          Conv2d-191           [32, 1536, 7, 7]       1,572,864\n",
      " SeparableConv2d-192           [32, 1536, 7, 7]               0\n",
      "     BatchNorm2d-193           [32, 1536, 7, 7]           3,072\n",
      "            ReLU-194           [32, 1536, 7, 7]               0\n",
      "          Conv2d-195           [32, 1536, 7, 7]          13,824\n",
      "          Conv2d-196           [32, 2048, 7, 7]       3,145,728\n",
      " SeparableConv2d-197           [32, 2048, 7, 7]               0\n",
      "     BatchNorm2d-198           [32, 2048, 7, 7]           4,096\n",
      "            ReLU-199           [32, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-200           [32, 2048, 1, 1]               0\n",
      "SelectAdaptivePool2d-201                 [32, 2048]               0\n",
      "          Linear-202                    [32, 7]          14,343\n",
      "        Xception-203                    [32, 7]               0\n",
      "================================================================\n",
      "Total params: 20,821,295\n",
      "Trainable params: 20,821,295\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.87\n",
      "Forward/backward pass size (MB): 12955.66\n",
      "Params size (MB): 79.43\n",
      "Estimated Total Size (MB): 13053.96\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31c28ac64f147e6b7c789326e79f06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5][0/43] || LR : 0.00002 || Train Loss : 1.9203 (1.9203) || Train Top 1-acc : 21.875% (21.875)% || Train Top 5-acc : 81.250% (81.250)%\n",
      "Epoch : [1/5][10/43] || LR : 0.00008 || Train Loss : 1.8480 (1.9122) || Train Top 1-acc : 37.500% (23.864)% || Train Top 5-acc : 90.625% (80.682)%\n",
      "Epoch : [1/5][20/43] || LR : 0.00010 || Train Loss : 1.5186 (1.8257) || Train Top 1-acc : 50.000% (29.762)% || Train Top 5-acc : 96.875% (85.714)%\n",
      "Epoch : [1/5][30/43] || LR : 0.00008 || Train Loss : 1.1210 (1.6956) || Train Top 1-acc : 75.000% (37.399)% || Train Top 5-acc : 96.875% (89.012)%\n",
      "Epoch : [1/5][40/43] || LR : 0.00006 || Train Loss : 0.7559 (1.5560) || Train Top 1-acc : 84.375% (44.512)% || Train Top 5-acc : 96.875% (91.159)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e4a5a07cd34c45986039019f0fbbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5] || Val Loss : 0.4834 || Val Top 1-acc : 92.647% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8060d15ef9c4b42856025a36ba8e480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5][0/43] || LR : 0.00005 || Train Loss : 0.7675 (0.7675) || Train Top 1-acc : 78.125% (78.125)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/5][10/43] || LR : 0.00003 || Train Loss : 0.5338 (1.0495) || Train Top 1-acc : 87.500% (69.318)% || Train Top 5-acc : 100.000% (95.739)%\n",
      "Epoch : [2/5][20/43] || LR : 0.00001 || Train Loss : 0.7972 (1.0243) || Train Top 1-acc : 87.500% (69.345)% || Train Top 5-acc : 100.000% (95.982)%\n",
      "Epoch : [2/5][30/43] || LR : 0.00002 || Train Loss : 1.0051 (0.9466) || Train Top 1-acc : 90.625% (71.169)% || Train Top 5-acc : 100.000% (96.169)%\n",
      "Epoch : [2/5][40/43] || LR : 0.00005 || Train Loss : 0.9586 (0.8539) || Train Top 1-acc : 87.500% (76.143)% || Train Top 5-acc : 100.000% (96.951)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0514638549b4914b9f789820a6fcf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5] || Val Loss : 0.3082 || Val Top 1-acc : 96.176% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd19feafc52490d83ac0406a8fbce5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5][0/43] || LR : 0.00005 || Train Loss : 0.3802 (0.3802) || Train Top 1-acc : 87.500% (87.500)% || Train Top 5-acc : 96.875% (96.875)%\n",
      "Epoch : [3/5][10/43] || LR : 0.00005 || Train Loss : 0.2869 (0.6715) || Train Top 1-acc : 96.875% (75.852)% || Train Top 5-acc : 100.000% (97.443)%\n",
      "Epoch : [3/5][20/43] || LR : 0.00004 || Train Loss : 0.5296 (0.7534) || Train Top 1-acc : 93.750% (76.786)% || Train Top 5-acc : 100.000% (97.917)%\n",
      "Epoch : [3/5][30/43] || LR : 0.00003 || Train Loss : 0.2400 (0.7004) || Train Top 1-acc : 100.000% (80.847)% || Train Top 5-acc : 100.000% (98.488)%\n",
      "Epoch : [3/5][40/43] || LR : 0.00002 || Train Loss : 1.1686 (0.7120) || Train Top 1-acc : 43.750% (79.116)% || Train Top 5-acc : 90.625% (98.095)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b118bbb3cb844869cd6b6355f09a269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5] || Val Loss : 0.2482 || Val Top 1-acc : 96.765% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f3d950c4b46f987aec3e0de654c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5][0/43] || LR : 0.00001 || Train Loss : 0.9188 (0.9188) || Train Top 1-acc : 31.250% (31.250)% || Train Top 5-acc : 87.500% (87.500)%\n",
      "Epoch : [4/5][10/43] || LR : 0.00001 || Train Loss : 0.1865 (0.6020) || Train Top 1-acc : 96.875% (82.955)% || Train Top 5-acc : 100.000% (98.580)%\n",
      "Epoch : [4/5][20/43] || LR : 0.00002 || Train Loss : 0.2276 (0.6334) || Train Top 1-acc : 100.000% (82.887)% || Train Top 5-acc : 100.000% (97.321)%\n",
      "Epoch : [4/5][30/43] || LR : 0.00002 || Train Loss : 1.5387 (0.7353) || Train Top 1-acc : 25.000% (77.621)% || Train Top 5-acc : 93.750% (97.379)%\n",
      "Epoch : [4/5][40/43] || LR : 0.00002 || Train Loss : 0.9877 (0.7028) || Train Top 1-acc : 87.500% (78.659)% || Train Top 5-acc : 100.000% (97.409)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7965693cbcfd4d20a2ee6b41aedd0f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5] || Val Loss : 0.2496 || Val Top 1-acc : 97.059% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ece5f5ba54246c3ac948fb9591ac709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5][0/43] || LR : 0.00002 || Train Loss : 1.1415 (1.1415) || Train Top 1-acc : 71.875% (71.875)% || Train Top 5-acc : 93.750% (93.750)%\n",
      "Epoch : [5/5][10/43] || LR : 0.00002 || Train Loss : 0.3550 (0.6978) || Train Top 1-acc : 100.000% (77.841)% || Train Top 5-acc : 100.000% (94.602)%\n",
      "Epoch : [5/5][20/43] || LR : 0.00001 || Train Loss : 0.2111 (0.6255) || Train Top 1-acc : 100.000% (83.631)% || Train Top 5-acc : 100.000% (96.875)%\n",
      "Epoch : [5/5][30/43] || LR : 0.00001 || Train Loss : 0.1992 (0.6200) || Train Top 1-acc : 96.875% (83.972)% || Train Top 5-acc : 100.000% (97.379)%\n",
      "Epoch : [5/5][40/43] || LR : 0.00001 || Train Loss : 0.0931 (0.5607) || Train Top 1-acc : 100.000% (86.662)% || Train Top 5-acc : 100.000% (98.018)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfefc7ffb0c48be88e13f8284599ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5] || Val Loss : 0.1927 || Val Top 1-acc : 97.353% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============2-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de54121c85d40008d6c587c639e350e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5][0/43] || LR : 0.00002 || Train Loss : 1.9223 (1.9223) || Train Top 1-acc : 21.875% (21.875)% || Train Top 5-acc : 81.250% (81.250)%\n",
      "Epoch : [1/5][10/43] || LR : 0.00008 || Train Loss : 1.8392 (1.9115) || Train Top 1-acc : 34.375% (21.307)% || Train Top 5-acc : 87.500% (81.818)%\n",
      "Epoch : [1/5][20/43] || LR : 0.00010 || Train Loss : 1.6471 (1.8243) || Train Top 1-acc : 37.500% (28.125)% || Train Top 5-acc : 96.875% (87.054)%\n",
      "Epoch : [1/5][30/43] || LR : 0.00008 || Train Loss : 1.1576 (1.7274) || Train Top 1-acc : 71.875% (33.065)% || Train Top 5-acc : 100.000% (88.609)%\n",
      "Epoch : [1/5][40/43] || LR : 0.00006 || Train Loss : 0.8240 (1.6136) || Train Top 1-acc : 81.250% (40.473)% || Train Top 5-acc : 100.000% (90.244)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a567eba64941d6b945462fc61e45bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5] || Val Loss : 0.4950 || Val Top 1-acc : 92.647% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcc290e53d14ed1af9ea1b6c95cb1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5][0/43] || LR : 0.00005 || Train Loss : 0.7855 (0.7855) || Train Top 1-acc : 84.375% (84.375)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/5][10/43] || LR : 0.00003 || Train Loss : 0.5936 (0.7464) || Train Top 1-acc : 93.750% (78.693)% || Train Top 5-acc : 100.000% (97.159)%\n",
      "Epoch : [2/5][20/43] || LR : 0.00001 || Train Loss : 0.5717 (0.8689) || Train Top 1-acc : 87.500% (78.274)% || Train Top 5-acc : 100.000% (97.173)%\n",
      "Epoch : [2/5][30/43] || LR : 0.00002 || Train Loss : 0.6279 (0.8218) || Train Top 1-acc : 78.125% (78.629)% || Train Top 5-acc : 100.000% (97.379)%\n",
      "Epoch : [2/5][40/43] || LR : 0.00005 || Train Loss : 1.3799 (0.8128) || Train Top 1-acc : 56.250% (79.116)% || Train Top 5-acc : 96.875% (97.713)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6245a0af0be4a7ebd5adba83e8ad316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5] || Val Loss : 0.2858 || Val Top 1-acc : 96.176% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085324484e2945caaf47f9fed79b38ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5][0/43] || LR : 0.00005 || Train Loss : 0.3456 (0.3456) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/5][10/43] || LR : 0.00005 || Train Loss : 1.4133 (0.9264) || Train Top 1-acc : 40.625% (69.602)% || Train Top 5-acc : 87.500% (96.023)%\n",
      "Epoch : [3/5][20/43] || LR : 0.00004 || Train Loss : 0.8683 (0.7701) || Train Top 1-acc : 93.750% (79.018)% || Train Top 5-acc : 96.875% (97.321)%\n",
      "Epoch : [3/5][30/43] || LR : 0.00003 || Train Loss : 0.3017 (0.7191) || Train Top 1-acc : 100.000% (79.536)% || Train Top 5-acc : 100.000% (97.581)%\n",
      "Epoch : [3/5][40/43] || LR : 0.00002 || Train Loss : 0.3100 (0.6492) || Train Top 1-acc : 93.750% (82.470)% || Train Top 5-acc : 100.000% (98.018)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0681ac168b9a40c6a1914293d35f71a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5] || Val Loss : 0.1768 || Val Top 1-acc : 97.647% || Val Top 5-acc : 99.706%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1b5e425f274c76a1c375fedcfea15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5][0/43] || LR : 0.00001 || Train Loss : 1.3125 (1.3125) || Train Top 1-acc : 40.625% (40.625)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/5][10/43] || LR : 0.00001 || Train Loss : 1.5986 (0.7030) || Train Top 1-acc : 31.250% (72.443)% || Train Top 5-acc : 90.625% (97.443)%\n",
      "Epoch : [4/5][20/43] || LR : 0.00002 || Train Loss : 0.7299 (0.6687) || Train Top 1-acc : 90.625% (81.399)% || Train Top 5-acc : 100.000% (98.512)%\n",
      "Epoch : [4/5][30/43] || LR : 0.00002 || Train Loss : 0.1231 (0.7180) || Train Top 1-acc : 100.000% (79.335)% || Train Top 5-acc : 100.000% (97.984)%\n",
      "Epoch : [4/5][40/43] || LR : 0.00002 || Train Loss : 0.1234 (0.7164) || Train Top 1-acc : 100.000% (77.058)% || Train Top 5-acc : 100.000% (97.942)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc759a4bf894f48bd2a724ba9d7d645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5] || Val Loss : 0.2127 || Val Top 1-acc : 97.647% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670052f6f7b8481cb9d8fd5ba980ef16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5][0/43] || LR : 0.00002 || Train Loss : 1.1118 (1.1118) || Train Top 1-acc : 71.875% (71.875)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/5][10/43] || LR : 0.00002 || Train Loss : 0.7215 (0.7230) || Train Top 1-acc : 93.750% (79.830)% || Train Top 5-acc : 100.000% (96.875)%\n",
      "Epoch : [5/5][20/43] || LR : 0.00001 || Train Loss : 0.1403 (0.5305) || Train Top 1-acc : 100.000% (87.054)% || Train Top 5-acc : 100.000% (98.363)%\n",
      "Epoch : [5/5][30/43] || LR : 0.00001 || Train Loss : 0.1886 (0.5688) || Train Top 1-acc : 96.875% (86.391)% || Train Top 5-acc : 100.000% (97.984)%\n",
      "Epoch : [5/5][40/43] || LR : 0.00001 || Train Loss : 1.3608 (0.6139) || Train Top 1-acc : 37.500% (84.604)% || Train Top 5-acc : 96.875% (97.942)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28381070d734815a6f8b1b47d135ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5] || Val Loss : 0.1855 || Val Top 1-acc : 97.941% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============3-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d19c2328fc4fa9a0e825b602d9a5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5][0/43] || LR : 0.00002 || Train Loss : 1.9670 (1.9670) || Train Top 1-acc : 15.625% (15.625)% || Train Top 5-acc : 68.750% (68.750)%\n",
      "Epoch : [1/5][10/43] || LR : 0.00008 || Train Loss : 1.8559 (1.9282) || Train Top 1-acc : 34.375% (16.761)% || Train Top 5-acc : 87.500% (75.852)%\n",
      "Epoch : [1/5][20/43] || LR : 0.00010 || Train Loss : 1.8224 (1.8658) || Train Top 1-acc : 31.250% (25.446)% || Train Top 5-acc : 87.500% (82.589)%\n",
      "Epoch : [1/5][30/43] || LR : 0.00008 || Train Loss : 1.1161 (1.7131) || Train Top 1-acc : 75.000% (38.105)% || Train Top 5-acc : 90.625% (85.786)%\n",
      "Epoch : [1/5][40/43] || LR : 0.00006 || Train Loss : 1.5691 (1.5651) || Train Top 1-acc : 43.750% (45.351)% || Train Top 5-acc : 90.625% (88.796)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16abb380fd754621973a9d13c31106b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5] || Val Loss : 0.5015 || Val Top 1-acc : 92.353% || Val Top 5-acc : 99.706%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79104438c67f4ebb993761b1f9aa2190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5][0/43] || LR : 0.00005 || Train Loss : 0.6781 (0.6781) || Train Top 1-acc : 87.500% (87.500)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/5][10/43] || LR : 0.00003 || Train Loss : 0.4105 (0.7941) || Train Top 1-acc : 90.625% (80.114)% || Train Top 5-acc : 100.000% (98.011)%\n",
      "Epoch : [2/5][20/43] || LR : 0.00001 || Train Loss : 0.5167 (0.8333) || Train Top 1-acc : 87.500% (79.167)% || Train Top 5-acc : 100.000% (97.321)%\n",
      "Epoch : [2/5][30/43] || LR : 0.00002 || Train Loss : 1.2400 (0.8937) || Train Top 1-acc : 65.625% (75.605)% || Train Top 5-acc : 100.000% (96.371)%\n",
      "Epoch : [2/5][40/43] || LR : 0.00005 || Train Loss : 0.9813 (0.8106) || Train Top 1-acc : 87.500% (79.192)% || Train Top 5-acc : 100.000% (97.104)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f2b23dd85747478e36b113fa6ba75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5] || Val Loss : 0.3283 || Val Top 1-acc : 95.294% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912c062509b94d4593d1c2c46257f6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5][0/43] || LR : 0.00005 || Train Loss : 0.2580 (0.2580) || Train Top 1-acc : 96.875% (96.875)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/5][10/43] || LR : 0.00005 || Train Loss : 1.2090 (0.7323) || Train Top 1-acc : 68.750% (80.398)% || Train Top 5-acc : 96.875% (95.739)%\n",
      "Epoch : [3/5][20/43] || LR : 0.00004 || Train Loss : 0.3418 (0.7781) || Train Top 1-acc : 90.625% (75.893)% || Train Top 5-acc : 100.000% (95.387)%\n",
      "Epoch : [3/5][30/43] || LR : 0.00003 || Train Loss : 0.3173 (0.7079) || Train Top 1-acc : 96.875% (78.427)% || Train Top 5-acc : 100.000% (95.968)%\n",
      "Epoch : [3/5][40/43] || LR : 0.00002 || Train Loss : 0.4002 (0.6562) || Train Top 1-acc : 84.375% (80.107)% || Train Top 5-acc : 100.000% (96.875)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dc1a2c99794f6dad31d932e2912062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5] || Val Loss : 0.2573 || Val Top 1-acc : 95.588% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4014c93e8344b8199f8a4f0854934f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5][0/43] || LR : 0.00001 || Train Loss : 0.2818 (0.2818) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/5][10/43] || LR : 0.00001 || Train Loss : 0.1384 (0.6770) || Train Top 1-acc : 100.000% (80.114)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [4/5][20/43] || LR : 0.00002 || Train Loss : 1.3945 (0.7529) || Train Top 1-acc : 15.625% (73.958)% || Train Top 5-acc : 93.750% (98.214)%\n",
      "Epoch : [4/5][30/43] || LR : 0.00002 || Train Loss : 1.1996 (0.7127) || Train Top 1-acc : 71.875% (75.605)% || Train Top 5-acc : 100.000% (97.782)%\n",
      "Epoch : [4/5][40/43] || LR : 0.00002 || Train Loss : 1.1492 (0.7329) || Train Top 1-acc : 65.625% (76.372)% || Train Top 5-acc : 100.000% (97.409)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be626f7ec69b4647a0ef046d78e4aeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5] || Val Loss : 0.2539 || Val Top 1-acc : 96.176% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3216174697124689b88cd9bf0a895f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5][0/43] || LR : 0.00002 || Train Loss : 0.1440 (0.1440) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/5][10/43] || LR : 0.00002 || Train Loss : 0.1117 (0.4564) || Train Top 1-acc : 100.000% (90.625)% || Train Top 5-acc : 100.000% (98.864)%\n",
      "Epoch : [5/5][20/43] || LR : 0.00001 || Train Loss : 1.3803 (0.5122) || Train Top 1-acc : 31.250% (85.417)% || Train Top 5-acc : 81.250% (97.917)%\n",
      "Epoch : [5/5][30/43] || LR : 0.00001 || Train Loss : 0.1066 (0.4303) || Train Top 1-acc : 100.000% (87.298)% || Train Top 5-acc : 100.000% (98.387)%\n",
      "Epoch : [5/5][40/43] || LR : 0.00001 || Train Loss : 0.0954 (0.4079) || Train Top 1-acc : 100.000% (88.643)% || Train Top 5-acc : 100.000% (98.323)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de564d2c5a82476c902677c9c9746aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5] || Val Loss : 0.1906 || Val Top 1-acc : 96.765% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============4-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8976e0d153674353b78a0415702c115f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5][0/43] || LR : 0.00002 || Train Loss : 1.9807 (1.9807) || Train Top 1-acc : 6.250% (6.250)% || Train Top 5-acc : 62.500% (62.500)%\n",
      "Epoch : [1/5][10/43] || LR : 0.00008 || Train Loss : 1.8926 (1.9440) || Train Top 1-acc : 21.875% (14.489)% || Train Top 5-acc : 96.875% (75.000)%\n",
      "Epoch : [1/5][20/43] || LR : 0.00010 || Train Loss : 1.6877 (1.8705) || Train Top 1-acc : 53.125% (26.637)% || Train Top 5-acc : 90.625% (83.333)%\n",
      "Epoch : [1/5][30/43] || LR : 0.00008 || Train Loss : 1.4514 (1.7214) || Train Top 1-acc : 34.375% (37.802)% || Train Top 5-acc : 87.500% (87.198)%\n",
      "Epoch : [1/5][40/43] || LR : 0.00006 || Train Loss : 0.9629 (1.5835) || Train Top 1-acc : 78.125% (44.665)% || Train Top 5-acc : 100.000% (88.872)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464e9765225343cf92331a96a5bcc8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5] || Val Loss : 0.5897 || Val Top 1-acc : 89.086% || Val Top 5-acc : 99.115%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78815edab8ee46e1b60ac9b1275c174c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5][0/43] || LR : 0.00005 || Train Loss : 1.3016 (1.3016) || Train Top 1-acc : 15.625% (15.625)% || Train Top 5-acc : 87.500% (87.500)%\n",
      "Epoch : [2/5][10/43] || LR : 0.00003 || Train Loss : 0.4033 (0.8551) || Train Top 1-acc : 90.625% (77.273)% || Train Top 5-acc : 100.000% (98.011)%\n",
      "Epoch : [2/5][20/43] || LR : 0.00001 || Train Loss : 0.7328 (0.8203) || Train Top 1-acc : 100.000% (75.744)% || Train Top 5-acc : 100.000% (97.321)%\n",
      "Epoch : [2/5][30/43] || LR : 0.00002 || Train Loss : 1.2078 (0.7729) || Train Top 1-acc : 40.625% (78.125)% || Train Top 5-acc : 100.000% (98.085)%\n",
      "Epoch : [2/5][40/43] || LR : 0.00005 || Train Loss : 0.3194 (0.7712) || Train Top 1-acc : 96.875% (78.277)% || Train Top 5-acc : 100.000% (97.866)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9e9cd589e24f52a3ad48b48c869c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5] || Val Loss : 0.3965 || Val Top 1-acc : 90.560% || Val Top 5-acc : 99.115%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c7df6ecd6047c6913b5a8a5ef44156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5][0/43] || LR : 0.00005 || Train Loss : 0.3515 (0.3515) || Train Top 1-acc : 90.625% (90.625)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/5][10/43] || LR : 0.00005 || Train Loss : 1.0856 (0.5254) || Train Top 1-acc : 93.750% (90.909)% || Train Top 5-acc : 96.875% (99.148)%\n",
      "Epoch : [3/5][20/43] || LR : 0.00004 || Train Loss : 0.3155 (0.5493) || Train Top 1-acc : 93.750% (88.839)% || Train Top 5-acc : 100.000% (98.214)%\n",
      "Epoch : [3/5][30/43] || LR : 0.00003 || Train Loss : 0.1985 (0.4975) || Train Top 1-acc : 93.750% (90.020)% || Train Top 5-acc : 100.000% (98.790)%\n",
      "Epoch : [3/5][40/43] || LR : 0.00002 || Train Loss : 0.1638 (0.5185) || Train Top 1-acc : 96.875% (89.024)% || Train Top 5-acc : 100.000% (98.476)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae133c70a1064520b163adcd69e697af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5] || Val Loss : 0.3052 || Val Top 1-acc : 92.920% || Val Top 5-acc : 99.705%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4201835938f4ababb1bcd04517dfc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5][0/43] || LR : 0.00001 || Train Loss : 0.3282 (0.3282) || Train Top 1-acc : 96.875% (96.875)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/5][10/43] || LR : 0.00001 || Train Loss : 1.2023 (0.8562) || Train Top 1-acc : 71.875% (70.455)% || Train Top 5-acc : 100.000% (97.159)%\n",
      "Epoch : [4/5][20/43] || LR : 0.00002 || Train Loss : 0.2844 (0.6832) || Train Top 1-acc : 93.750% (79.762)% || Train Top 5-acc : 100.000% (98.363)%\n",
      "Epoch : [4/5][30/43] || LR : 0.00002 || Train Loss : 0.1341 (0.6180) || Train Top 1-acc : 96.875% (82.056)% || Train Top 5-acc : 100.000% (98.387)%\n",
      "Epoch : [4/5][40/43] || LR : 0.00002 || Train Loss : 0.7878 (0.6376) || Train Top 1-acc : 87.500% (80.869)% || Train Top 5-acc : 100.000% (98.171)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e80f2aa3cc431f9c8b599e09021b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5] || Val Loss : 0.2939 || Val Top 1-acc : 94.100% || Val Top 5-acc : 99.705%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f09b2bae4684a4ca91cc3dca89b2314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5][0/43] || LR : 0.00002 || Train Loss : 0.7430 (0.7430) || Train Top 1-acc : 96.875% (96.875)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/5][10/43] || LR : 0.00002 || Train Loss : 1.2862 (0.7751) || Train Top 1-acc : 34.375% (79.830)% || Train Top 5-acc : 90.625% (98.864)%\n",
      "Epoch : [5/5][20/43] || LR : 0.00001 || Train Loss : 1.4696 (0.6656) || Train Top 1-acc : 28.125% (80.655)% || Train Top 5-acc : 90.625% (98.363)%\n",
      "Epoch : [5/5][30/43] || LR : 0.00001 || Train Loss : 0.1067 (0.5903) || Train Top 1-acc : 100.000% (80.242)% || Train Top 5-acc : 100.000% (97.581)%\n",
      "Epoch : [5/5][40/43] || LR : 0.00001 || Train Loss : 0.2489 (0.5192) || Train Top 1-acc : 93.750% (83.994)% || Train Top 5-acc : 100.000% (98.171)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e972d18fc54192b7f649810b0c2e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5] || Val Loss : 0.2686 || Val Top 1-acc : 94.985% || Val Top 5-acc : 99.705%\n",
      "\n",
      "\n",
      "'===============5-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f008cfcc2eb9467e9e11f6caf2a8991b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5][0/43] || LR : 0.00002 || Train Loss : 1.9370 (1.9370) || Train Top 1-acc : 21.875% (21.875)% || Train Top 5-acc : 68.750% (68.750)%\n",
      "Epoch : [1/5][10/43] || LR : 0.00008 || Train Loss : 1.9181 (1.9284) || Train Top 1-acc : 28.125% (18.750)% || Train Top 5-acc : 81.250% (76.705)%\n",
      "Epoch : [1/5][20/43] || LR : 0.00010 || Train Loss : 1.7258 (1.8563) || Train Top 1-acc : 46.875% (28.720)% || Train Top 5-acc : 96.875% (83.482)%\n",
      "Epoch : [1/5][30/43] || LR : 0.00008 || Train Loss : 0.8337 (1.7009) || Train Top 1-acc : 90.625% (40.524)% || Train Top 5-acc : 100.000% (87.601)%\n",
      "Epoch : [1/5][40/43] || LR : 0.00006 || Train Loss : 0.7957 (1.5443) || Train Top 1-acc : 81.250% (48.018)% || Train Top 5-acc : 100.000% (89.939)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4cdb6e26764355b6a9ae1d97647733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/5] || Val Loss : 0.6502 || Val Top 1-acc : 82.596% || Val Top 5-acc : 98.525%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e3e2e825474424ab6eefb29a4cd023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5][0/43] || LR : 0.00005 || Train Loss : 0.5541 (0.5541) || Train Top 1-acc : 90.625% (90.625)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/5][10/43] || LR : 0.00003 || Train Loss : 0.3884 (0.7828) || Train Top 1-acc : 93.750% (78.977)% || Train Top 5-acc : 100.000% (96.591)%\n",
      "Epoch : [2/5][20/43] || LR : 0.00001 || Train Loss : 1.2102 (0.7854) || Train Top 1-acc : 81.250% (79.315)% || Train Top 5-acc : 96.875% (96.875)%\n",
      "Epoch : [2/5][30/43] || LR : 0.00002 || Train Loss : 1.0425 (0.8321) || Train Top 1-acc : 81.250% (75.101)% || Train Top 5-acc : 100.000% (95.968)%\n",
      "Epoch : [2/5][40/43] || LR : 0.00005 || Train Loss : 1.5090 (0.8408) || Train Top 1-acc : 28.125% (76.143)% || Train Top 5-acc : 84.375% (96.341)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81b8cb40c95476fae65246317aa0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/5] || Val Loss : 0.4726 || Val Top 1-acc : 91.445% || Val Top 5-acc : 99.705%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc816edd44ae4ee195a46e9f2f63b0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5][0/43] || LR : 0.00005 || Train Loss : 0.2571 (0.2571) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/5][10/43] || LR : 0.00005 || Train Loss : 0.1653 (0.4482) || Train Top 1-acc : 100.000% (85.795)% || Train Top 5-acc : 100.000% (98.580)%\n",
      "Epoch : [3/5][20/43] || LR : 0.00004 || Train Loss : 0.4610 (0.4116) || Train Top 1-acc : 96.875% (90.476)% || Train Top 5-acc : 100.000% (99.107)%\n",
      "Epoch : [3/5][30/43] || LR : 0.00003 || Train Loss : 1.0448 (0.5106) || Train Top 1-acc : 84.375% (86.290)% || Train Top 5-acc : 100.000% (98.387)%\n",
      "Epoch : [3/5][40/43] || LR : 0.00002 || Train Loss : 0.5503 (0.5365) || Train Top 1-acc : 90.625% (85.366)% || Train Top 5-acc : 100.000% (98.399)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637927c9d64d47d1a4cc27662d1981dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/5] || Val Loss : 0.4061 || Val Top 1-acc : 92.330% || Val Top 5-acc : 99.115%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c27e8416e47487891811996ff5249c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5][0/43] || LR : 0.00001 || Train Loss : 0.0869 (0.0869) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/5][10/43] || LR : 0.00001 || Train Loss : 1.1783 (0.7143) || Train Top 1-acc : 71.875% (78.693)% || Train Top 5-acc : 100.000% (96.875)%\n",
      "Epoch : [4/5][20/43] || LR : 0.00002 || Train Loss : 0.1454 (0.6725) || Train Top 1-acc : 100.000% (77.083)% || Train Top 5-acc : 100.000% (96.875)%\n",
      "Epoch : [4/5][30/43] || LR : 0.00002 || Train Loss : 0.3005 (0.7633) || Train Top 1-acc : 93.750% (72.480)% || Train Top 5-acc : 100.000% (96.371)%\n",
      "Epoch : [4/5][40/43] || LR : 0.00002 || Train Loss : 0.8749 (0.7099) || Train Top 1-acc : 90.625% (75.000)% || Train Top 5-acc : 96.875% (96.570)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eadd920129a47dd8d11b43bddb63a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/5] || Val Loss : 0.3896 || Val Top 1-acc : 92.035% || Val Top 5-acc : 99.410%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed713fcac5a74e379916937df322aa30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5][0/43] || LR : 0.00002 || Train Loss : 0.9653 (0.9653) || Train Top 1-acc : 84.375% (84.375)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/5][10/43] || LR : 0.00002 || Train Loss : 0.9112 (0.6103) || Train Top 1-acc : 87.500% (77.841)% || Train Top 5-acc : 100.000% (99.148)%\n",
      "Epoch : [5/5][20/43] || LR : 0.00001 || Train Loss : 0.0831 (0.5784) || Train Top 1-acc : 100.000% (81.399)% || Train Top 5-acc : 100.000% (99.107)%\n",
      "Epoch : [5/5][30/43] || LR : 0.00001 || Train Loss : 1.3651 (0.6546) || Train Top 1-acc : 53.125% (78.427)% || Train Top 5-acc : 96.875% (97.883)%\n",
      "Epoch : [5/5][40/43] || LR : 0.00001 || Train Loss : 0.7441 (0.6678) || Train Top 1-acc : 93.750% (78.125)% || Train Top 5-acc : 100.000% (98.171)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b337260dec1840db996db1db6f0b4d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/5] || Val Loss : 0.3823 || Val Top 1-acc : 92.625% || Val Top 5-acc : 99.410%\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=cfg.values.train_args.n_splits)\n",
    "k = 1\n",
    "for train_idx, val_idx in kfold.split(whole_df, whole_label):\n",
    "    print('\\n')\n",
    "    cpprint('=' * 15 + f'{k}-Fold Cross Validation' + '=' * 15)\n",
    "    train_df = whole_df.iloc[train_idx]\n",
    "    val_df = whole_df.iloc[val_idx]\n",
    "\n",
    "    train_loader = get_dataloader(df=train_df, transform=train_transform, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    val_loader = get_dataloader(df=val_df, transform=val_transform, batch_size=VAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    train(cfg, k, train_loader, val_loader)\n",
    "\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "- Test Time Augmentation 사용 (only hflip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, data_path='./test/0/', transform=None):\n",
    "#         self.data_path = data_path\n",
    "#         self.data = os.listdir(data_path)\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):        \n",
    "#         image_path = os.path.join(self.data_path, self.data[idx])\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image=np.array(image))['image']\n",
    "            \n",
    "#         return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 77  \n",
    "# BATCH_SIZE = 32    \n",
    "# IMAGE_SIZE = 227\n",
    "# MODEL_ARC = 'nfnet_l0'\n",
    "# NUM_CLASSES = 7\n",
    "# MODEL_DIR = './results'\n",
    "# NUM_FOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix random seed\n",
    "# def seed_everything(seed: int = 42):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)  # type: ignore\n",
    "#     torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "#     torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_transform = albumentations.Compose([               \n",
    "#         albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "#         albumentations.Normalize(mean=(0.4569, 0.5074, 0.5557), std=(0.2888, 0.2743, 0.2829)),\n",
    "#         albumentations.pytorch.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TestDataset(transform=test_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PretrainedModel(nn.Module):\n",
    "#     def __init__(self, model_arc='swin_tiny_patch4_window7_224', num_classes=7):\n",
    "#         super().__init__()\n",
    "#         self.net = timm.create_model(model_arc, pretrained=False, num_classes=num_classes)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.net(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = PretrainedModel(model_arc=MODEL_ARC, num_classes=NUM_CLASSES)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# states = [torch.load(glob(MODEL_DIR + f'/{MODEL_ARC}/{k}_fold/*.pth')[-1]) for k in range(1, NUM_FOLD + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transforms = tta.Compose(\n",
    "#     [\n",
    "#         tta.HorizontalFlip(),\n",
    "#         # tta.VerticalFlip(),\n",
    "#         # tta.Multiply(factors=[0.9, 1, 1.1])\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model ensemble을 위해서 npy 파일 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = []\n",
    "# save_ = []\n",
    "# for i, images in enumerate(tqdm(test_loader)):\n",
    "#     images = images.to(device)\n",
    "#     avg_preds = []\n",
    "#     for state in states:\n",
    "#         model.load_state_dict(state)\n",
    "#         model.eval()\n",
    "#         tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "#         tta_model.to(device)\n",
    "#         tta_model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             logits = tta_model(images)\n",
    "#         avg_preds.append(logits.to('cpu').numpy())\n",
    "#     avg_preds = np.mean(avg_preds, axis=0)\n",
    "#     save_.append(avg_preds)\n",
    "#     probs.append(avg_preds.argmax(-1))\n",
    "# save_ = np.concatenate(save_)\n",
    "# probs = np.concatenate(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./test_answer_sample_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'./{MODEL_ARC}.npy', save_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['answer value'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'submission_{MODEL_ARC}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "- nfnet_l0와 swin transformer 사용\n",
    "- stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy_list = [\n",
    "#     'nfnet_l0.npy',\n",
    "#     'swin_base_patch4_window7_224.npy'\n",
    "# ]\n",
    "\n",
    "# predictions = []\n",
    "# for f in npy_list:\n",
    "#     predictions.append(np.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = np.array(predictions).mean(axis=0).argmax(-1)\n",
    "# final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./test_answer_sample_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['answer value'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'submission_ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNHgfiaLWAfJXDLoBnx7ayu",
   "collapsed_sections": [],
   "name": "eda.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
