{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "- EDA를 진행하면서 동시에 csv를 만들었습니다.\n",
    "- image와 label을 반환합니다.\n",
    "- albumentations augmentation을 염두해두고 설계했기 때문에 이미지를 opencv로 읽었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtPaintDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index()\n",
    "        self.image_id = self.df.image_id\n",
    "        self.labels = self.df.label\n",
    "        self.transform = transform        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def set_transform(self, transform):        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_id[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "\n",
    "        return {'image' : image, 'label' : label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import timm\n",
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from adamp import AdamP\n",
    "from easydict import EasyDict\n",
    "from prettyprinter import cpprint\n",
    "from torchsummary import summary as summary_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConfigManager\n",
    "- .yaml 파일을 사용하여 config를 관리했습니다.\n",
    "- config를 바꿔가며 실험했습니다.\n",
    "- 최종적으로 사용한 config는 다음과 같습니다.\n",
    "---\n",
    "```\n",
    "base:\n",
    "  seed: 77\n",
    "  model_arc: 'nfnet_l0'\n",
    "  num_classes: 7\n",
    "  input_dir: './train/train.csv'\n",
    "  output_dir: './results/'\n",
    "  train_only: False\n",
    "  image_size: 227\n",
    "  cutmix_args:\n",
    "    use_cutmix: False\n",
    "    beta: 1.0\n",
    "    cutmix_prob: 0.5\n",
    "  train_args:\n",
    "    num_epochs: 6\n",
    "    train_batch_size: 32\n",
    "    val_batch_size: 32\n",
    "    max_lr: 0.0001\n",
    "    min_lr: 0.00001\n",
    "    cycle: 3\n",
    "    gamma: 0.5\n",
    "    weight_decay: 0.000001\n",
    "    log_intervals: 10\n",
    "    eval_metric: 'accuracy'    \n",
    "    n_splits: 5\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "swin:\n",
    "  seed: 777\n",
    "  model_arc: 'swin_base_patch4_window7_224'\n",
    "  num_classes: 7\n",
    "  input_dir: './train/train.csv'\n",
    "  output_dir: './results/'\n",
    "  train_only: False\n",
    "  image_size: 224\n",
    "  cutmix_args:\n",
    "    use_cutmix: True\n",
    "    beta: 1.0\n",
    "    cutmix_prob: 0.5\n",
    "  train_args:\n",
    "    num_epochs: 10\n",
    "    train_batch_size: 16\n",
    "    val_batch_size: 16\n",
    "    max_lr: 0.0001\n",
    "    min_lr: 0.00001\n",
    "    cycle: 3\n",
    "    gamma: 0.5\n",
    "    weight_decay: 0.000001\n",
    "    log_intervals: 10\n",
    "    eval_metric: 'accuracy'    \n",
    "    n_splits: 5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Config\n",
    "class YamlConfigManager:\n",
    "    def __init__(self, config_file_path='./config.yml', config_name='swin'):\n",
    "        super().__init__()\n",
    "        self.values = EasyDict()        \n",
    "        if config_file_path:\n",
    "            self.config_file_path = config_file_path\n",
    "            self.config_name = config_name\n",
    "            self.reload()\n",
    "    \n",
    "    def reload(self):\n",
    "        self.clear()\n",
    "        if self.config_file_path:\n",
    "            with open(self.config_file_path, 'r') as f:\n",
    "                self.values.update(yaml.safe_load(f)[self.config_name])\n",
    "\n",
    "    def clear(self):\n",
    "        self.values.clear()\n",
    "    \n",
    "    def update(self, yml_dict):\n",
    "        for (k1, v1) in yml_dict.items():\n",
    "            if isinstance(v1, dict):\n",
    "                for (k2, v2) in v1.items():\n",
    "                    if isinstance(v2, dict):\n",
    "                        for (k3, v3) in v2.items():\n",
    "                            self.values[k1][k2][k3] = v3\n",
    "                    else:\n",
    "                        self.values[k1][k2] = v2\n",
    "            else:\n",
    "                self.values[k1] = v1\n",
    "\n",
    "    def export(self, save_file_path):\n",
    "        if save_file_path:\n",
    "            with open(save_file_path, 'w') as f:\n",
    "                yaml.dump(dict(self.values), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = YamlConfigManager()\n",
    "\n",
    "SEED = cfg.values.seed\n",
    "INPUT_DIR = cfg.values.input_dir\n",
    "TRAIN_ONLY = cfg.values.train_only\n",
    "IMAGE_SIZE = cfg.values.image_size\n",
    "TRAIN_BATCH_SIZE = cfg.values.train_args.train_batch_size\n",
    "VAL_BATCH_SIZE = cfg.values.train_args.val_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEED 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- 만들어둔 csv 파일을 불러왔습니다.\n",
    "\n",
    "### Augmentation\n",
    "- HorizontalFlip() : TTA를 염두해두고 선택하였습니다.\n",
    "- ToGray() : 그림 이미지라서 색조가 너무 다양할 것이라고 생각하여 gray scale에서도 feature를 잡을 수 있었으면 했습니다.\n",
    "- Blur() : 그림 이미지 특성상 blurring된 효과가 많이 있을 것이라 생각하여 채택했습니다.\n",
    "- Normalize RGB mean, std 값은 eda.ipynb를 통해 직접 계산했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1621735577479,
     "user": {
      "displayName": "김효진",
      "photoUrl": "",
      "userId": "06712056052855259710"
     },
     "user_tz": -540
    },
    "id": "9MajXDBf-BRL",
    "outputId": "a8f46576-f639-448c-bddf-ce18c30ca06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4569, 0.5074, 0.5557])\n",
      "std:  tensor([0.2888, 0.2743, 0.2829])\n"
     ]
    }
   ],
   "source": [
    "# # Caculate mean and std\n",
    "\n",
    "# # pixel count\n",
    "# count = len(train_df) * 227 * 227\n",
    "\n",
    "# # mean and std\n",
    "# total_mean = psum / count\n",
    "# total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "# total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# # output\n",
    "# print('mean: '  + str(total_mean))\n",
    "# print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = pd.read_csv(INPUT_DIR)\n",
    "whole_label = whole_df['label'].values\n",
    "\n",
    "train_transform = albumentations.Compose([\n",
    "    albumentations.OneOf([\n",
    "        albumentations.HorizontalFlip(),\n",
    "        albumentations.ToGray(),\n",
    "        albumentations.Blur()\n",
    "    ]), \n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albumentations.Normalize(mean=(0.4569, 0.5074, 0.5557), std=(0.2888, 0.2743, 0.2829)),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "val_transform = albumentations.Compose([\n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albumentations.Normalize(mean=(0.4569, 0.5074, 0.5557), std=(0.2888, 0.2743, 0.2829)),\n",
    "    albumentations.pytorch.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- timm library를 사용했습니다.\n",
    "- NFNet, EfficientNet\n",
    "    - kaggle ailen signal search 대회에 참가 중인데 nfnet과 efficientnet이 대체로 성능이 좋았습니다.\n",
    "    - 첫 제출 당시에 NFNet을 사용했는데 1.0이 나와서 놀랐습니다. \n",
    "    - 문제가 쉬운 대회인 만큼 shake up이 심할거라 생각해서 다른 모델들도 테스트했지만 val score가 좋지 않았습니다.\n",
    "    - LB score\n",
    "        - efficientnet_b0 : `90.0`\n",
    "        - nfnet_l0 : `100.0`\n",
    "- Swin-transformer\n",
    "    - naver boostcamp에서 competition 진행했었는데 detection 대회에서 swin-transformer를 사용해서 2등을 했습니다.\n",
    "    - 당시에 성능이 좋았습니다.\n",
    "    - 구조가 다른 모델끼리 앙상블할 경우에 generalized performance가 올라갈 것이라고 생각했습니다. \n",
    "    - LB score\n",
    "        - swin-base-224-22k : `97.14`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, model_arc='resnet18d', num_classes=7):\n",
    "        super().__init__()\n",
    "        self.net = timm.create_model(model_arc, pretrained=True, num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils\n",
    "- 여러가지 유틸 함수들을 정의했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(df, transform, batch_size, shuffle):\n",
    "    dataset = ArtPaintDataset(df=df, transform=transform)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CosineAnnealingWarmupRestarts\n",
    "- gamma 비율로 감소하는 cosine annealing warmup restart scheduler가 lr 분석하기 제일 편했습니다.\n",
    "- 경험에 의해서 선택했으며, wandb와 함께 사용할 경우 optimizer 분석에 매우 용이했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
    "    \"\"\"\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        first_cycle_steps (int): First cycle step size.\n",
    "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
    "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
    "        min_lr(float): Min learning rate. Default: 0.001.\n",
    "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
    "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 optimizer : torch.optim.Optimizer,\n",
    "                 first_cycle_steps : int,\n",
    "                 cycle_mult : float = 1.,\n",
    "                 max_lr : float = 0.1,\n",
    "                 min_lr : float = 0.001,\n",
    "                 warmup_steps : int = 0,\n",
    "                 gamma : float = 1.,\n",
    "                 last_epoch : int = -1\n",
    "        ):\n",
    "        assert warmup_steps < first_cycle_steps\n",
    "        \n",
    "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
    "        self.base_max_lr = max_lr # first max learning rate\n",
    "        self.max_lr = max_lr # max learning rate in the current cycle\n",
    "        self.min_lr = min_lr # min learning rate\n",
    "        self.warmup_steps = warmup_steps # warmup step size\n",
    "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
    "        \n",
    "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
    "        self.cycle = 0 # cycle count\n",
    "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
    "        \n",
    "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
    "        \n",
    "        # set learning rate min_lr\n",
    "        self.init_lr()\n",
    "    \n",
    "    def init_lr(self):\n",
    "        self.base_lrs = []\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = self.min_lr\n",
    "            self.base_lrs.append(self.min_lr)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.step_in_cycle == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.step_in_cycle < self.warmup_steps:\n",
    "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.max_lr - base_lr) \\\n",
    "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
    "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.step_in_cycle = self.step_in_cycle + 1\n",
    "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
    "                self.cycle += 1\n",
    "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
    "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
    "        else:\n",
    "            if epoch >= self.first_cycle_steps:\n",
    "                if self.cycle_mult == 1.:\n",
    "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
    "                    self.cycle = epoch // self.first_cycle_steps\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
    "                    self.cycle = n\n",
    "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
    "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
    "            else:\n",
    "                self.cur_cycle_steps = self.first_cycle_steps\n",
    "                self.step_in_cycle = epoch\n",
    "                \n",
    "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CutMix\n",
    "- Robust한 모델을 만들기 위해 선택한 방법입니다.\n",
    "- 쉬운 문제에서 사용할 경우 성능이 많이 좋아졌었던 경험이 있습니다.\n",
    "- 학습을 더욱 복잡하게 만들어서 generalized performance의 향상을 노렸습니다.\n",
    "- NFNet에서는 사용하지 않았고, Swin Transformer에만 사용해서 앙상블했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    width = size[2]\n",
    "    height = size[3]\n",
    "    cut_ratio = np.sqrt(1. - lam)\n",
    "    cut_width = np.int(width * cut_ratio)\n",
    "    cut_height = np.int(height * cut_ratio)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(width)\n",
    "    cy = np.random.randint(height)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_width // 2, 0, width)\n",
    "    bby1 = np.clip(cy - cut_height // 2, 0, height)\n",
    "    bbx2 = np.clip(cx + cut_width // 2, 0, width)\n",
    "    bby2 = np.clip(cy + cut_height // 2, 0, height)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutMix(object):\n",
    "    def __init__(self, beta, cutmix_prob) -> None:\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.cutmix_prob = cutmix_prob \n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        # generate mixed sample\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        rand_index = torch.randperm(images.size()[0]).cuda()\n",
    "        label_1 = labels\n",
    "        label_2 = labels[rand_index]\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "        images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "        # adjust lambda to exactly match pixel ratio\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
    "\n",
    "        return {'lam' : lam, 'image' : images, 'label_1' : label_1, 'label_2' : label_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMetric(object):\n",
    "    def __init__(self, metric) -> None:\n",
    "        super().__init__() \n",
    "        self.metric = metric    \n",
    "\n",
    "    def cutmix_accuracy(self, logits, labels, topk=(1, 5)):\n",
    "        max_k = max(topk)\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        _, pred = logits.topk(max_k, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        matches = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            matches_k = matches[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            wrong_k = batch_size - matches_k\n",
    "            res.append(matches_k.mul_(100.0 / batch_size))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def compute(self, logits, labels, topk=(1, 5)):\n",
    "        if self.metric == 'accuracy':\n",
    "            out = self.cutmix_accuracy(logits=logits, labels=labels, topk=topk)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지표 계산을 위한 average meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    " - 5 Fold cross validation 사용\n",
    " - 모델 별로 lr, epoch 조절해가면서 다르게 학습했습니다.\n",
    " - EDA(eda.ipynb 파일 만들어서 진행) 해봤을 때 guitar와 person같이 class imbalance가 있어 stratified하게 train과 validation 분할 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KHJ\\Anaconda3\\envs\\ustage\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib as pyplot\n",
    "# import seaborn as sns\n",
    "\n",
    "# ax = sns.countplot(train_df['label'])\n",
    "\n",
    "# for p, label in zip(ax.patches, label_list):\n",
    "#     ax.annotate(label, (p.get_x(), p.get_height() + 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg, k, train_loader, val_loader):\n",
    "    # Set Config\n",
    "    MODEL_ARC = cfg.values.model_arc\n",
    "    OUTPUT_DIR = cfg.values.output_dir\n",
    "    NUM_CLASSES = cfg.values.num_classes\n",
    "    TRAIN_ONLY = cfg.values.train_only\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Set train arguments\n",
    "    num_epochs = cfg.values.train_args.num_epochs\n",
    "    train_batch_size = cfg.values.train_args.train_batch_size\n",
    "    log_intervals = cfg.values.train_args.log_intervals\n",
    "    max_lr = cfg.values.train_args.max_lr\n",
    "    min_lr = cfg.values.train_args.min_lr\n",
    "    cycle = cfg.values.train_args.cycle\n",
    "    gamma = cfg.values.train_args.gamma\n",
    "\n",
    "    # Set CutMix arguments\n",
    "    USE_CUTMIX = cfg.values.cutmix_args.use_cutmix    \n",
    "    beta = cfg.values.cutmix_args.beta\n",
    "    cutmix_prob = cfg.values.cutmix_args.cutmix_prob    \n",
    "    cutmix = CutMix(beta=beta, cutmix_prob=cutmix_prob)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = PretrainedModel(model_arc=MODEL_ARC, num_classes=NUM_CLASSES)\n",
    "    model.to(device)\n",
    "    if k < 2:\n",
    "        summary_(model, (3, IMAGE_SIZE, IMAGE_SIZE), batch_size=train_batch_size)\n",
    "\n",
    "    optimizer = AdamP(model.parameters(), lr=max_lr, weight_decay=cfg.values.train_args.weight_decay)\n",
    "    first_cycle_steps = len(train_loader) * num_epochs // cycle\n",
    "    scheduler = CosineAnnealingWarmupRestarts(\n",
    "        optimizer, \n",
    "        first_cycle_steps=first_cycle_steps, \n",
    "        cycle_mult=1.0,\n",
    "        max_lr=max_lr, \n",
    "        min_lr=min_lr, \n",
    "        warmup_steps=int(first_cycle_steps * 0.2), \n",
    "        gamma=gamma\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    eval_metric = ComputeMetric(cfg.values.train_args.eval_metric)\n",
    "    best_acc = 0.\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, MODEL_ARC), exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_values = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "\n",
    "        for i, train_batch in enumerate(tqdm(train_loader, desc=f'Training')):\n",
    "            sample = train_batch\n",
    "            images = sample['image'].float().to(device)\n",
    "            labels = sample['label'].long().to(device)\n",
    "\n",
    "            ratio = np.random.rand(1)\n",
    "\n",
    "            if USE_CUTMIX:\n",
    "                if beta > 0 and ratio < cutmix_prob:\n",
    "                    # generate mixed sample\n",
    "                    sample = cutmix.forward(images, labels)\n",
    "\n",
    "                    logits = model(sample['image'])                    \n",
    "                    loss = criterion(logits, sample['label_1']) * sample['lam'] + criterion(logits, sample['label_2']) * (1. - sample['lam'])\n",
    "                else:\n",
    "                    logits = model(images)\n",
    "                    loss = criterion(logits, labels)\n",
    "            else:\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "            # measure evaluation metric and record loss\n",
    "            top1_err, top5_err = eval_metric.compute(logits.data, labels, topk=(1, 5))\n",
    "\n",
    "            loss_values.update(loss.item(), images.size(0))\n",
    "            top1.update(top1_err.item(), images.size(0))\n",
    "            top5.update(top5_err.item(), images.size(0))\n",
    "\n",
    "            # compute gradient and do optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if i % log_intervals == 0:\n",
    "                current_lr = scheduler.get_lr()[0]\n",
    "                tqdm.write(f'Epoch : [{epoch + 1}/{num_epochs}][{i}/{len(train_loader)}] || '\n",
    "                           f'LR : {current_lr:.5f} || '\n",
    "                           f'Train Loss : {loss_values.val:.4f} ({loss_values.avg:.4f}) || '                        \n",
    "                           f'Train Top 1-acc : {top1.val:.3f}% ({top1.avg:.3f})% || '\n",
    "                           f'Train Top 5-acc : {top5.val:.3f}% ({top5.avg:.3f})%')\n",
    "\n",
    "        loss_values = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "        \n",
    "        if not TRAIN_ONLY:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                loss_values = AverageMeter()\n",
    "                top1 = AverageMeter()\n",
    "                top5 = AverageMeter()\n",
    "\n",
    "                for i, val_batch in enumerate(tqdm(val_loader, desc=f'Validation')):\n",
    "                    sample = val_batch\n",
    "                    images = sample['image'].float().to(device)\n",
    "                    labels = sample['label'].long().to(device)\n",
    "\n",
    "                    logits = model(images)\n",
    "                    loss = criterion(logits, labels)\n",
    "                    preds = torch.argmax(logits, -1)\n",
    "\n",
    "                    top1_err, top5_err = eval_metric.compute(logits.data, labels, topk=(1, 5))\n",
    "                    loss_values.update(loss.item(), images.size(0))\n",
    "                    top1.update(top1_err.item(), images.size(0))\n",
    "                    top5.update(top5_err.item(), images.size(0))\n",
    "\n",
    "            tqdm.write(f'Epoch : [{epoch + 1}/{num_epochs}] || '\n",
    "                       f'Val Loss : {loss_values.avg:.4f} || '                        \n",
    "                       f'Val Top 1-acc : {top1.avg:.3f}% || '\n",
    "                       f'Val Top 5-acc : {top5.avg:.3f}%')\n",
    "\n",
    "            is_best = top1.avg >= best_acc\n",
    "            best_acc = max(top1.avg, best_acc)\n",
    "\n",
    "            if is_best:\n",
    "                if k > 0:\n",
    "                    os.makedirs(os.path.join(OUTPUT_DIR, MODEL_ARC, f'{k}_fold'), exist_ok=True)\n",
    "                    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, MODEL_ARC, f'{k}_fold', f'{epoch + 1}_epoch_{best_acc:.2f}%_with_val.pth'))\n",
    "                else:                    \n",
    "                    torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, MODEL_ARC, f'{epoch + 1}_epoch_{best_acc:.2f}%_with_val.pth'))\n",
    "        \n",
    "        else:\n",
    "            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, MODEL_ARC, f'_{epoch + 1}_epoch_{top1.avg:.2f}%_only_train.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "'===============1-Fold Cross Validation==============='\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [16, 128, 56, 56]           6,272\n",
      "         LayerNorm-2            [16, 3136, 128]             256\n",
      "        PatchEmbed-3            [16, 3136, 128]               0\n",
      "           Dropout-4            [16, 3136, 128]               0\n",
      "         LayerNorm-5            [16, 3136, 128]             256\n",
      "            Linear-6              [16, 49, 384]          49,536\n",
      "           Softmax-7            [16, 4, 49, 49]               0\n",
      "           Dropout-8            [16, 4, 49, 49]               0\n",
      "            Linear-9              [16, 49, 128]          16,512\n",
      "          Dropout-10              [16, 49, 128]               0\n",
      "  WindowAttention-11              [16, 49, 128]               0\n",
      "         Identity-12            [16, 3136, 128]               0\n",
      "        LayerNorm-13            [16, 3136, 128]             256\n",
      "           Linear-14            [16, 3136, 512]          66,048\n",
      "             GELU-15            [16, 3136, 512]               0\n",
      "          Dropout-16            [16, 3136, 512]               0\n",
      "           Linear-17            [16, 3136, 128]          65,664\n",
      "          Dropout-18            [16, 3136, 128]               0\n",
      "              Mlp-19            [16, 3136, 128]               0\n",
      "         Identity-20            [16, 3136, 128]               0\n",
      "SwinTransformerBlock-21            [16, 3136, 128]               0\n",
      "        LayerNorm-22            [16, 3136, 128]             256\n",
      "           Linear-23              [16, 49, 384]          49,536\n",
      "          Softmax-24            [16, 4, 49, 49]               0\n",
      "          Dropout-25            [16, 4, 49, 49]               0\n",
      "           Linear-26              [16, 49, 128]          16,512\n",
      "          Dropout-27              [16, 49, 128]               0\n",
      "  WindowAttention-28              [16, 49, 128]               0\n",
      "         DropPath-29            [16, 3136, 128]               0\n",
      "        LayerNorm-30            [16, 3136, 128]             256\n",
      "           Linear-31            [16, 3136, 512]          66,048\n",
      "             GELU-32            [16, 3136, 512]               0\n",
      "          Dropout-33            [16, 3136, 512]               0\n",
      "           Linear-34            [16, 3136, 128]          65,664\n",
      "          Dropout-35            [16, 3136, 128]               0\n",
      "              Mlp-36            [16, 3136, 128]               0\n",
      "         DropPath-37            [16, 3136, 128]               0\n",
      "SwinTransformerBlock-38            [16, 3136, 128]               0\n",
      "        LayerNorm-39             [16, 784, 512]           1,024\n",
      "           Linear-40             [16, 784, 256]         131,072\n",
      "     PatchMerging-41             [16, 784, 256]               0\n",
      "       BasicLayer-42             [16, 784, 256]               0\n",
      "        LayerNorm-43             [16, 784, 256]             512\n",
      "           Linear-44              [16, 49, 768]         197,376\n",
      "          Softmax-45            [16, 8, 49, 49]               0\n",
      "          Dropout-46            [16, 8, 49, 49]               0\n",
      "           Linear-47              [16, 49, 256]          65,792\n",
      "          Dropout-48              [16, 49, 256]               0\n",
      "  WindowAttention-49              [16, 49, 256]               0\n",
      "         DropPath-50             [16, 784, 256]               0\n",
      "        LayerNorm-51             [16, 784, 256]             512\n",
      "           Linear-52            [16, 784, 1024]         263,168\n",
      "             GELU-53            [16, 784, 1024]               0\n",
      "          Dropout-54            [16, 784, 1024]               0\n",
      "           Linear-55             [16, 784, 256]         262,400\n",
      "          Dropout-56             [16, 784, 256]               0\n",
      "              Mlp-57             [16, 784, 256]               0\n",
      "         DropPath-58             [16, 784, 256]               0\n",
      "SwinTransformerBlock-59             [16, 784, 256]               0\n",
      "        LayerNorm-60             [16, 784, 256]             512\n",
      "           Linear-61              [16, 49, 768]         197,376\n",
      "          Softmax-62            [16, 8, 49, 49]               0\n",
      "          Dropout-63            [16, 8, 49, 49]               0\n",
      "           Linear-64              [16, 49, 256]          65,792\n",
      "          Dropout-65              [16, 49, 256]               0\n",
      "  WindowAttention-66              [16, 49, 256]               0\n",
      "         DropPath-67             [16, 784, 256]               0\n",
      "        LayerNorm-68             [16, 784, 256]             512\n",
      "           Linear-69            [16, 784, 1024]         263,168\n",
      "             GELU-70            [16, 784, 1024]               0\n",
      "          Dropout-71            [16, 784, 1024]               0\n",
      "           Linear-72             [16, 784, 256]         262,400\n",
      "          Dropout-73             [16, 784, 256]               0\n",
      "              Mlp-74             [16, 784, 256]               0\n",
      "         DropPath-75             [16, 784, 256]               0\n",
      "SwinTransformerBlock-76             [16, 784, 256]               0\n",
      "        LayerNorm-77            [16, 196, 1024]           2,048\n",
      "           Linear-78             [16, 196, 512]         524,288\n",
      "     PatchMerging-79             [16, 196, 512]               0\n",
      "       BasicLayer-80             [16, 196, 512]               0\n",
      "        LayerNorm-81             [16, 196, 512]           1,024\n",
      "           Linear-82             [16, 49, 1536]         787,968\n",
      "          Softmax-83           [16, 16, 49, 49]               0\n",
      "          Dropout-84           [16, 16, 49, 49]               0\n",
      "           Linear-85              [16, 49, 512]         262,656\n",
      "          Dropout-86              [16, 49, 512]               0\n",
      "  WindowAttention-87              [16, 49, 512]               0\n",
      "         DropPath-88             [16, 196, 512]               0\n",
      "        LayerNorm-89             [16, 196, 512]           1,024\n",
      "           Linear-90            [16, 196, 2048]       1,050,624\n",
      "             GELU-91            [16, 196, 2048]               0\n",
      "          Dropout-92            [16, 196, 2048]               0\n",
      "           Linear-93             [16, 196, 512]       1,049,088\n",
      "          Dropout-94             [16, 196, 512]               0\n",
      "              Mlp-95             [16, 196, 512]               0\n",
      "         DropPath-96             [16, 196, 512]               0\n",
      "SwinTransformerBlock-97             [16, 196, 512]               0\n",
      "        LayerNorm-98             [16, 196, 512]           1,024\n",
      "           Linear-99             [16, 49, 1536]         787,968\n",
      "         Softmax-100           [16, 16, 49, 49]               0\n",
      "         Dropout-101           [16, 16, 49, 49]               0\n",
      "          Linear-102              [16, 49, 512]         262,656\n",
      "         Dropout-103              [16, 49, 512]               0\n",
      " WindowAttention-104              [16, 49, 512]               0\n",
      "        DropPath-105             [16, 196, 512]               0\n",
      "       LayerNorm-106             [16, 196, 512]           1,024\n",
      "          Linear-107            [16, 196, 2048]       1,050,624\n",
      "            GELU-108            [16, 196, 2048]               0\n",
      "         Dropout-109            [16, 196, 2048]               0\n",
      "          Linear-110             [16, 196, 512]       1,049,088\n",
      "         Dropout-111             [16, 196, 512]               0\n",
      "             Mlp-112             [16, 196, 512]               0\n",
      "        DropPath-113             [16, 196, 512]               0\n",
      "SwinTransformerBlock-114             [16, 196, 512]               0\n",
      "       LayerNorm-115             [16, 196, 512]           1,024\n",
      "          Linear-116             [16, 49, 1536]         787,968\n",
      "         Softmax-117           [16, 16, 49, 49]               0\n",
      "         Dropout-118           [16, 16, 49, 49]               0\n",
      "          Linear-119              [16, 49, 512]         262,656\n",
      "         Dropout-120              [16, 49, 512]               0\n",
      " WindowAttention-121              [16, 49, 512]               0\n",
      "        DropPath-122             [16, 196, 512]               0\n",
      "       LayerNorm-123             [16, 196, 512]           1,024\n",
      "          Linear-124            [16, 196, 2048]       1,050,624\n",
      "            GELU-125            [16, 196, 2048]               0\n",
      "         Dropout-126            [16, 196, 2048]               0\n",
      "          Linear-127             [16, 196, 512]       1,049,088\n",
      "         Dropout-128             [16, 196, 512]               0\n",
      "             Mlp-129             [16, 196, 512]               0\n",
      "        DropPath-130             [16, 196, 512]               0\n",
      "SwinTransformerBlock-131             [16, 196, 512]               0\n",
      "       LayerNorm-132             [16, 196, 512]           1,024\n",
      "          Linear-133             [16, 49, 1536]         787,968\n",
      "         Softmax-134           [16, 16, 49, 49]               0\n",
      "         Dropout-135           [16, 16, 49, 49]               0\n",
      "          Linear-136              [16, 49, 512]         262,656\n",
      "         Dropout-137              [16, 49, 512]               0\n",
      " WindowAttention-138              [16, 49, 512]               0\n",
      "        DropPath-139             [16, 196, 512]               0\n",
      "       LayerNorm-140             [16, 196, 512]           1,024\n",
      "          Linear-141            [16, 196, 2048]       1,050,624\n",
      "            GELU-142            [16, 196, 2048]               0\n",
      "         Dropout-143            [16, 196, 2048]               0\n",
      "          Linear-144             [16, 196, 512]       1,049,088\n",
      "         Dropout-145             [16, 196, 512]               0\n",
      "             Mlp-146             [16, 196, 512]               0\n",
      "        DropPath-147             [16, 196, 512]               0\n",
      "SwinTransformerBlock-148             [16, 196, 512]               0\n",
      "       LayerNorm-149             [16, 196, 512]           1,024\n",
      "          Linear-150             [16, 49, 1536]         787,968\n",
      "         Softmax-151           [16, 16, 49, 49]               0\n",
      "         Dropout-152           [16, 16, 49, 49]               0\n",
      "          Linear-153              [16, 49, 512]         262,656\n",
      "         Dropout-154              [16, 49, 512]               0\n",
      " WindowAttention-155              [16, 49, 512]               0\n",
      "        DropPath-156             [16, 196, 512]               0\n",
      "       LayerNorm-157             [16, 196, 512]           1,024\n",
      "          Linear-158            [16, 196, 2048]       1,050,624\n",
      "            GELU-159            [16, 196, 2048]               0\n",
      "         Dropout-160            [16, 196, 2048]               0\n",
      "          Linear-161             [16, 196, 512]       1,049,088\n",
      "         Dropout-162             [16, 196, 512]               0\n",
      "             Mlp-163             [16, 196, 512]               0\n",
      "        DropPath-164             [16, 196, 512]               0\n",
      "SwinTransformerBlock-165             [16, 196, 512]               0\n",
      "       LayerNorm-166             [16, 196, 512]           1,024\n",
      "          Linear-167             [16, 49, 1536]         787,968\n",
      "         Softmax-168           [16, 16, 49, 49]               0\n",
      "         Dropout-169           [16, 16, 49, 49]               0\n",
      "          Linear-170              [16, 49, 512]         262,656\n",
      "         Dropout-171              [16, 49, 512]               0\n",
      " WindowAttention-172              [16, 49, 512]               0\n",
      "        DropPath-173             [16, 196, 512]               0\n",
      "       LayerNorm-174             [16, 196, 512]           1,024\n",
      "          Linear-175            [16, 196, 2048]       1,050,624\n",
      "            GELU-176            [16, 196, 2048]               0\n",
      "         Dropout-177            [16, 196, 2048]               0\n",
      "          Linear-178             [16, 196, 512]       1,049,088\n",
      "         Dropout-179             [16, 196, 512]               0\n",
      "             Mlp-180             [16, 196, 512]               0\n",
      "        DropPath-181             [16, 196, 512]               0\n",
      "SwinTransformerBlock-182             [16, 196, 512]               0\n",
      "       LayerNorm-183             [16, 196, 512]           1,024\n",
      "          Linear-184             [16, 49, 1536]         787,968\n",
      "         Softmax-185           [16, 16, 49, 49]               0\n",
      "         Dropout-186           [16, 16, 49, 49]               0\n",
      "          Linear-187              [16, 49, 512]         262,656\n",
      "         Dropout-188              [16, 49, 512]               0\n",
      " WindowAttention-189              [16, 49, 512]               0\n",
      "        DropPath-190             [16, 196, 512]               0\n",
      "       LayerNorm-191             [16, 196, 512]           1,024\n",
      "          Linear-192            [16, 196, 2048]       1,050,624\n",
      "            GELU-193            [16, 196, 2048]               0\n",
      "         Dropout-194            [16, 196, 2048]               0\n",
      "          Linear-195             [16, 196, 512]       1,049,088\n",
      "         Dropout-196             [16, 196, 512]               0\n",
      "             Mlp-197             [16, 196, 512]               0\n",
      "        DropPath-198             [16, 196, 512]               0\n",
      "SwinTransformerBlock-199             [16, 196, 512]               0\n",
      "       LayerNorm-200             [16, 196, 512]           1,024\n",
      "          Linear-201             [16, 49, 1536]         787,968\n",
      "         Softmax-202           [16, 16, 49, 49]               0\n",
      "         Dropout-203           [16, 16, 49, 49]               0\n",
      "          Linear-204              [16, 49, 512]         262,656\n",
      "         Dropout-205              [16, 49, 512]               0\n",
      " WindowAttention-206              [16, 49, 512]               0\n",
      "        DropPath-207             [16, 196, 512]               0\n",
      "       LayerNorm-208             [16, 196, 512]           1,024\n",
      "          Linear-209            [16, 196, 2048]       1,050,624\n",
      "            GELU-210            [16, 196, 2048]               0\n",
      "         Dropout-211            [16, 196, 2048]               0\n",
      "          Linear-212             [16, 196, 512]       1,049,088\n",
      "         Dropout-213             [16, 196, 512]               0\n",
      "             Mlp-214             [16, 196, 512]               0\n",
      "        DropPath-215             [16, 196, 512]               0\n",
      "SwinTransformerBlock-216             [16, 196, 512]               0\n",
      "       LayerNorm-217             [16, 196, 512]           1,024\n",
      "          Linear-218             [16, 49, 1536]         787,968\n",
      "         Softmax-219           [16, 16, 49, 49]               0\n",
      "         Dropout-220           [16, 16, 49, 49]               0\n",
      "          Linear-221              [16, 49, 512]         262,656\n",
      "         Dropout-222              [16, 49, 512]               0\n",
      " WindowAttention-223              [16, 49, 512]               0\n",
      "        DropPath-224             [16, 196, 512]               0\n",
      "       LayerNorm-225             [16, 196, 512]           1,024\n",
      "          Linear-226            [16, 196, 2048]       1,050,624\n",
      "            GELU-227            [16, 196, 2048]               0\n",
      "         Dropout-228            [16, 196, 2048]               0\n",
      "          Linear-229             [16, 196, 512]       1,049,088\n",
      "         Dropout-230             [16, 196, 512]               0\n",
      "             Mlp-231             [16, 196, 512]               0\n",
      "        DropPath-232             [16, 196, 512]               0\n",
      "SwinTransformerBlock-233             [16, 196, 512]               0\n",
      "       LayerNorm-234             [16, 196, 512]           1,024\n",
      "          Linear-235             [16, 49, 1536]         787,968\n",
      "         Softmax-236           [16, 16, 49, 49]               0\n",
      "         Dropout-237           [16, 16, 49, 49]               0\n",
      "          Linear-238              [16, 49, 512]         262,656\n",
      "         Dropout-239              [16, 49, 512]               0\n",
      " WindowAttention-240              [16, 49, 512]               0\n",
      "        DropPath-241             [16, 196, 512]               0\n",
      "       LayerNorm-242             [16, 196, 512]           1,024\n",
      "          Linear-243            [16, 196, 2048]       1,050,624\n",
      "            GELU-244            [16, 196, 2048]               0\n",
      "         Dropout-245            [16, 196, 2048]               0\n",
      "          Linear-246             [16, 196, 512]       1,049,088\n",
      "         Dropout-247             [16, 196, 512]               0\n",
      "             Mlp-248             [16, 196, 512]               0\n",
      "        DropPath-249             [16, 196, 512]               0\n",
      "SwinTransformerBlock-250             [16, 196, 512]               0\n",
      "       LayerNorm-251             [16, 196, 512]           1,024\n",
      "          Linear-252             [16, 49, 1536]         787,968\n",
      "         Softmax-253           [16, 16, 49, 49]               0\n",
      "         Dropout-254           [16, 16, 49, 49]               0\n",
      "          Linear-255              [16, 49, 512]         262,656\n",
      "         Dropout-256              [16, 49, 512]               0\n",
      " WindowAttention-257              [16, 49, 512]               0\n",
      "        DropPath-258             [16, 196, 512]               0\n",
      "       LayerNorm-259             [16, 196, 512]           1,024\n",
      "          Linear-260            [16, 196, 2048]       1,050,624\n",
      "            GELU-261            [16, 196, 2048]               0\n",
      "         Dropout-262            [16, 196, 2048]               0\n",
      "          Linear-263             [16, 196, 512]       1,049,088\n",
      "         Dropout-264             [16, 196, 512]               0\n",
      "             Mlp-265             [16, 196, 512]               0\n",
      "        DropPath-266             [16, 196, 512]               0\n",
      "SwinTransformerBlock-267             [16, 196, 512]               0\n",
      "       LayerNorm-268             [16, 196, 512]           1,024\n",
      "          Linear-269             [16, 49, 1536]         787,968\n",
      "         Softmax-270           [16, 16, 49, 49]               0\n",
      "         Dropout-271           [16, 16, 49, 49]               0\n",
      "          Linear-272              [16, 49, 512]         262,656\n",
      "         Dropout-273              [16, 49, 512]               0\n",
      " WindowAttention-274              [16, 49, 512]               0\n",
      "        DropPath-275             [16, 196, 512]               0\n",
      "       LayerNorm-276             [16, 196, 512]           1,024\n",
      "          Linear-277            [16, 196, 2048]       1,050,624\n",
      "            GELU-278            [16, 196, 2048]               0\n",
      "         Dropout-279            [16, 196, 2048]               0\n",
      "          Linear-280             [16, 196, 512]       1,049,088\n",
      "         Dropout-281             [16, 196, 512]               0\n",
      "             Mlp-282             [16, 196, 512]               0\n",
      "        DropPath-283             [16, 196, 512]               0\n",
      "SwinTransformerBlock-284             [16, 196, 512]               0\n",
      "       LayerNorm-285             [16, 196, 512]           1,024\n",
      "          Linear-286             [16, 49, 1536]         787,968\n",
      "         Softmax-287           [16, 16, 49, 49]               0\n",
      "         Dropout-288           [16, 16, 49, 49]               0\n",
      "          Linear-289              [16, 49, 512]         262,656\n",
      "         Dropout-290              [16, 49, 512]               0\n",
      " WindowAttention-291              [16, 49, 512]               0\n",
      "        DropPath-292             [16, 196, 512]               0\n",
      "       LayerNorm-293             [16, 196, 512]           1,024\n",
      "          Linear-294            [16, 196, 2048]       1,050,624\n",
      "            GELU-295            [16, 196, 2048]               0\n",
      "         Dropout-296            [16, 196, 2048]               0\n",
      "          Linear-297             [16, 196, 512]       1,049,088\n",
      "         Dropout-298             [16, 196, 512]               0\n",
      "             Mlp-299             [16, 196, 512]               0\n",
      "        DropPath-300             [16, 196, 512]               0\n",
      "SwinTransformerBlock-301             [16, 196, 512]               0\n",
      "       LayerNorm-302             [16, 196, 512]           1,024\n",
      "          Linear-303             [16, 49, 1536]         787,968\n",
      "         Softmax-304           [16, 16, 49, 49]               0\n",
      "         Dropout-305           [16, 16, 49, 49]               0\n",
      "          Linear-306              [16, 49, 512]         262,656\n",
      "         Dropout-307              [16, 49, 512]               0\n",
      " WindowAttention-308              [16, 49, 512]               0\n",
      "        DropPath-309             [16, 196, 512]               0\n",
      "       LayerNorm-310             [16, 196, 512]           1,024\n",
      "          Linear-311            [16, 196, 2048]       1,050,624\n",
      "            GELU-312            [16, 196, 2048]               0\n",
      "         Dropout-313            [16, 196, 2048]               0\n",
      "          Linear-314             [16, 196, 512]       1,049,088\n",
      "         Dropout-315             [16, 196, 512]               0\n",
      "             Mlp-316             [16, 196, 512]               0\n",
      "        DropPath-317             [16, 196, 512]               0\n",
      "SwinTransformerBlock-318             [16, 196, 512]               0\n",
      "       LayerNorm-319             [16, 196, 512]           1,024\n",
      "          Linear-320             [16, 49, 1536]         787,968\n",
      "         Softmax-321           [16, 16, 49, 49]               0\n",
      "         Dropout-322           [16, 16, 49, 49]               0\n",
      "          Linear-323              [16, 49, 512]         262,656\n",
      "         Dropout-324              [16, 49, 512]               0\n",
      " WindowAttention-325              [16, 49, 512]               0\n",
      "        DropPath-326             [16, 196, 512]               0\n",
      "       LayerNorm-327             [16, 196, 512]           1,024\n",
      "          Linear-328            [16, 196, 2048]       1,050,624\n",
      "            GELU-329            [16, 196, 2048]               0\n",
      "         Dropout-330            [16, 196, 2048]               0\n",
      "          Linear-331             [16, 196, 512]       1,049,088\n",
      "         Dropout-332             [16, 196, 512]               0\n",
      "             Mlp-333             [16, 196, 512]               0\n",
      "        DropPath-334             [16, 196, 512]               0\n",
      "SwinTransformerBlock-335             [16, 196, 512]               0\n",
      "       LayerNorm-336             [16, 196, 512]           1,024\n",
      "          Linear-337             [16, 49, 1536]         787,968\n",
      "         Softmax-338           [16, 16, 49, 49]               0\n",
      "         Dropout-339           [16, 16, 49, 49]               0\n",
      "          Linear-340              [16, 49, 512]         262,656\n",
      "         Dropout-341              [16, 49, 512]               0\n",
      " WindowAttention-342              [16, 49, 512]               0\n",
      "        DropPath-343             [16, 196, 512]               0\n",
      "       LayerNorm-344             [16, 196, 512]           1,024\n",
      "          Linear-345            [16, 196, 2048]       1,050,624\n",
      "            GELU-346            [16, 196, 2048]               0\n",
      "         Dropout-347            [16, 196, 2048]               0\n",
      "          Linear-348             [16, 196, 512]       1,049,088\n",
      "         Dropout-349             [16, 196, 512]               0\n",
      "             Mlp-350             [16, 196, 512]               0\n",
      "        DropPath-351             [16, 196, 512]               0\n",
      "SwinTransformerBlock-352             [16, 196, 512]               0\n",
      "       LayerNorm-353             [16, 196, 512]           1,024\n",
      "          Linear-354             [16, 49, 1536]         787,968\n",
      "         Softmax-355           [16, 16, 49, 49]               0\n",
      "         Dropout-356           [16, 16, 49, 49]               0\n",
      "          Linear-357              [16, 49, 512]         262,656\n",
      "         Dropout-358              [16, 49, 512]               0\n",
      " WindowAttention-359              [16, 49, 512]               0\n",
      "        DropPath-360             [16, 196, 512]               0\n",
      "       LayerNorm-361             [16, 196, 512]           1,024\n",
      "          Linear-362            [16, 196, 2048]       1,050,624\n",
      "            GELU-363            [16, 196, 2048]               0\n",
      "         Dropout-364            [16, 196, 2048]               0\n",
      "          Linear-365             [16, 196, 512]       1,049,088\n",
      "         Dropout-366             [16, 196, 512]               0\n",
      "             Mlp-367             [16, 196, 512]               0\n",
      "        DropPath-368             [16, 196, 512]               0\n",
      "SwinTransformerBlock-369             [16, 196, 512]               0\n",
      "       LayerNorm-370             [16, 196, 512]           1,024\n",
      "          Linear-371             [16, 49, 1536]         787,968\n",
      "         Softmax-372           [16, 16, 49, 49]               0\n",
      "         Dropout-373           [16, 16, 49, 49]               0\n",
      "          Linear-374              [16, 49, 512]         262,656\n",
      "         Dropout-375              [16, 49, 512]               0\n",
      " WindowAttention-376              [16, 49, 512]               0\n",
      "        DropPath-377             [16, 196, 512]               0\n",
      "       LayerNorm-378             [16, 196, 512]           1,024\n",
      "          Linear-379            [16, 196, 2048]       1,050,624\n",
      "            GELU-380            [16, 196, 2048]               0\n",
      "         Dropout-381            [16, 196, 2048]               0\n",
      "          Linear-382             [16, 196, 512]       1,049,088\n",
      "         Dropout-383             [16, 196, 512]               0\n",
      "             Mlp-384             [16, 196, 512]               0\n",
      "        DropPath-385             [16, 196, 512]               0\n",
      "SwinTransformerBlock-386             [16, 196, 512]               0\n",
      "       LayerNorm-387             [16, 49, 2048]           4,096\n",
      "          Linear-388             [16, 49, 1024]       2,097,152\n",
      "    PatchMerging-389             [16, 49, 1024]               0\n",
      "      BasicLayer-390             [16, 49, 1024]               0\n",
      "       LayerNorm-391             [16, 49, 1024]           2,048\n",
      "          Linear-392             [16, 49, 3072]       3,148,800\n",
      "         Softmax-393           [16, 32, 49, 49]               0\n",
      "         Dropout-394           [16, 32, 49, 49]               0\n",
      "          Linear-395             [16, 49, 1024]       1,049,600\n",
      "         Dropout-396             [16, 49, 1024]               0\n",
      " WindowAttention-397             [16, 49, 1024]               0\n",
      "        DropPath-398             [16, 49, 1024]               0\n",
      "       LayerNorm-399             [16, 49, 1024]           2,048\n",
      "          Linear-400             [16, 49, 4096]       4,198,400\n",
      "            GELU-401             [16, 49, 4096]               0\n",
      "         Dropout-402             [16, 49, 4096]               0\n",
      "          Linear-403             [16, 49, 1024]       4,195,328\n",
      "         Dropout-404             [16, 49, 1024]               0\n",
      "             Mlp-405             [16, 49, 1024]               0\n",
      "        DropPath-406             [16, 49, 1024]               0\n",
      "SwinTransformerBlock-407             [16, 49, 1024]               0\n",
      "       LayerNorm-408             [16, 49, 1024]           2,048\n",
      "          Linear-409             [16, 49, 3072]       3,148,800\n",
      "         Softmax-410           [16, 32, 49, 49]               0\n",
      "         Dropout-411           [16, 32, 49, 49]               0\n",
      "          Linear-412             [16, 49, 1024]       1,049,600\n",
      "         Dropout-413             [16, 49, 1024]               0\n",
      " WindowAttention-414             [16, 49, 1024]               0\n",
      "        DropPath-415             [16, 49, 1024]               0\n",
      "       LayerNorm-416             [16, 49, 1024]           2,048\n",
      "          Linear-417             [16, 49, 4096]       4,198,400\n",
      "            GELU-418             [16, 49, 4096]               0\n",
      "         Dropout-419             [16, 49, 4096]               0\n",
      "          Linear-420             [16, 49, 1024]       4,195,328\n",
      "         Dropout-421             [16, 49, 1024]               0\n",
      "             Mlp-422             [16, 49, 1024]               0\n",
      "        DropPath-423             [16, 49, 1024]               0\n",
      "SwinTransformerBlock-424             [16, 49, 1024]               0\n",
      "      BasicLayer-425             [16, 49, 1024]               0\n",
      "       LayerNorm-426             [16, 49, 1024]           2,048\n",
      "AdaptiveAvgPool1d-427              [16, 1024, 1]               0\n",
      "          Linear-428                    [16, 7]           7,175\n",
      " SwinTransformer-429                    [16, 7]               0\n",
      "================================================================\n",
      "Total params: 86,686,855\n",
      "Trainable params: 86,686,855\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 8669.97\n",
      "Params size (MB): 330.68\n",
      "Estimated Total Size (MB): 9009.84\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6060ff0a4495420e8452f7e56b413a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10][0/85] || LR : 0.00001 || Train Loss : 2.1090 (2.1090) || Train Top 1-acc : 12.500% (12.500)% || Train Top 5-acc : 62.500% (62.500)%\n",
      "Epoch : [1/10][10/85] || LR : 0.00003 || Train Loss : 1.8202 (1.9161) || Train Top 1-acc : 25.000% (19.318)% || Train Top 5-acc : 87.500% (80.682)%\n",
      "Epoch : [1/10][20/85] || LR : 0.00004 || Train Loss : 1.1825 (1.7320) || Train Top 1-acc : 68.750% (34.226)% || Train Top 5-acc : 93.750% (86.012)%\n",
      "Epoch : [1/10][30/85] || LR : 0.00006 || Train Loss : 1.3470 (1.5649) || Train Top 1-acc : 62.500% (44.556)% || Train Top 5-acc : 100.000% (89.113)%\n",
      "Epoch : [1/10][40/85] || LR : 0.00008 || Train Loss : 0.2557 (1.3340) || Train Top 1-acc : 93.750% (53.659)% || Train Top 5-acc : 100.000% (91.159)%\n",
      "Epoch : [1/10][50/85] || LR : 0.00009 || Train Loss : 0.1729 (1.1790) || Train Top 1-acc : 93.750% (59.191)% || Train Top 5-acc : 100.000% (92.525)%\n",
      "Epoch : [1/10][60/85] || LR : 0.00010 || Train Loss : 1.3103 (1.1023) || Train Top 1-acc : 75.000% (61.988)% || Train Top 5-acc : 100.000% (93.443)%\n",
      "Epoch : [1/10][70/85] || LR : 0.00010 || Train Loss : 0.4908 (1.0439) || Train Top 1-acc : 87.500% (64.261)% || Train Top 5-acc : 100.000% (94.014)%\n",
      "Epoch : [1/10][80/85] || LR : 0.00010 || Train Loss : 0.8526 (0.9797) || Train Top 1-acc : 18.750% (66.975)% || Train Top 5-acc : 100.000% (94.753)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094eaaea40c640acb5c74ed6ebcdb7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10] || Val Loss : 0.1027 || Val Top 1-acc : 97.059% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac35e25de00e44af81f9e9adc629e6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10][0/85] || LR : 0.00010 || Train Loss : 1.0165 (1.0165) || Train Top 1-acc : 81.250% (81.250)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/10][10/85] || LR : 0.00009 || Train Loss : 0.1882 (0.4326) || Train Top 1-acc : 93.750% (92.614)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [2/10][20/85] || LR : 0.00009 || Train Loss : 0.0179 (0.4095) || Train Top 1-acc : 100.000% (88.393)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [2/10][30/85] || LR : 0.00009 || Train Loss : 0.1978 (0.4609) || Train Top 1-acc : 93.750% (87.702)% || Train Top 5-acc : 100.000% (99.194)%\n",
      "Epoch : [2/10][40/85] || LR : 0.00008 || Train Loss : 0.3267 (0.4471) || Train Top 1-acc : 87.500% (88.110)% || Train Top 5-acc : 100.000% (99.238)%\n",
      "Epoch : [2/10][50/85] || LR : 0.00008 || Train Loss : 0.8365 (0.4656) || Train Top 1-acc : 68.750% (88.235)% || Train Top 5-acc : 100.000% (99.387)%\n",
      "Epoch : [2/10][60/85] || LR : 0.00007 || Train Loss : 0.0348 (0.4488) || Train Top 1-acc : 100.000% (88.525)% || Train Top 5-acc : 100.000% (99.385)%\n",
      "Epoch : [2/10][70/85] || LR : 0.00006 || Train Loss : 0.2624 (0.4268) || Train Top 1-acc : 93.750% (88.732)% || Train Top 5-acc : 100.000% (99.472)%\n",
      "Epoch : [2/10][80/85] || LR : 0.00006 || Train Loss : 0.0438 (0.4027) || Train Top 1-acc : 100.000% (88.657)% || Train Top 5-acc : 100.000% (99.537)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8a858f90ec4decbde8958894eec684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10] || Val Loss : 0.0685 || Val Top 1-acc : 97.941% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3427d1f034e49dab9201b0628425f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10][0/85] || LR : 0.00005 || Train Loss : 0.6699 (0.6699) || Train Top 1-acc : 37.500% (37.500)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][10/85] || LR : 0.00005 || Train Loss : 0.0201 (0.1761) || Train Top 1-acc : 100.000% (92.614)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][20/85] || LR : 0.00004 || Train Loss : 0.0125 (0.2776) || Train Top 1-acc : 100.000% (94.345)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][30/85] || LR : 0.00004 || Train Loss : 0.6409 (0.3282) || Train Top 1-acc : 100.000% (92.137)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [3/10][40/85] || LR : 0.00003 || Train Loss : 0.0147 (0.3249) || Train Top 1-acc : 100.000% (92.835)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [3/10][50/85] || LR : 0.00003 || Train Loss : 0.0040 (0.2935) || Train Top 1-acc : 100.000% (93.873)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [3/10][60/85] || LR : 0.00002 || Train Loss : 0.0191 (0.2901) || Train Top 1-acc : 100.000% (94.570)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [3/10][70/85] || LR : 0.00002 || Train Loss : 0.0112 (0.2966) || Train Top 1-acc : 100.000% (93.662)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [3/10][80/85] || LR : 0.00001 || Train Loss : 0.0798 (0.2730) || Train Top 1-acc : 100.000% (94.444)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f39e74be654fc886303c93cf34fad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10] || Val Loss : 0.0472 || Val Top 1-acc : 98.824% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7321cd5f454b03b5e9bbb362dacd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10][0/85] || LR : 0.00001 || Train Loss : 0.0122 (0.0122) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][10/85] || LR : 0.00001 || Train Loss : 0.8667 (0.3944) || Train Top 1-acc : 87.500% (86.932)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][20/85] || LR : 0.00001 || Train Loss : 0.0085 (0.3728) || Train Top 1-acc : 100.000% (90.774)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][30/85] || LR : 0.00001 || Train Loss : 0.0063 (0.3491) || Train Top 1-acc : 100.000% (90.323)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][40/85] || LR : 0.00002 || Train Loss : 0.0090 (0.3131) || Train Top 1-acc : 100.000% (89.482)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][50/85] || LR : 0.00003 || Train Loss : 0.2690 (0.2854) || Train Top 1-acc : 100.000% (90.564)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][60/85] || LR : 0.00003 || Train Loss : 0.6340 (0.2916) || Train Top 1-acc : 93.750% (90.266)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][70/85] || LR : 0.00004 || Train Loss : 0.9933 (0.3147) || Train Top 1-acc : 12.500% (89.525)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [4/10][80/85] || LR : 0.00005 || Train Loss : 0.0077 (0.2940) || Train Top 1-acc : 100.000% (89.969)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d9a6cb9f574bf2bf3bb14ffa5194df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10] || Val Loss : 0.0554 || Val Top 1-acc : 98.529% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9beb9d6c49446e877e3ff01ea20bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10][0/85] || LR : 0.00005 || Train Loss : 0.7766 (0.7766) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][10/85] || LR : 0.00005 || Train Loss : 0.6723 (0.4551) || Train Top 1-acc : 100.000% (89.205)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [5/10][20/85] || LR : 0.00005 || Train Loss : 0.4227 (0.4078) || Train Top 1-acc : 100.000% (87.798)% || Train Top 5-acc : 100.000% (99.702)%\n",
      "Epoch : [5/10][30/85] || LR : 0.00005 || Train Loss : 0.6683 (0.4091) || Train Top 1-acc : 87.500% (87.298)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [5/10][40/85] || LR : 0.00005 || Train Loss : 0.0084 (0.4049) || Train Top 1-acc : 100.000% (87.957)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [5/10][50/85] || LR : 0.00005 || Train Loss : 0.0036 (0.3768) || Train Top 1-acc : 100.000% (89.583)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [5/10][60/85] || LR : 0.00004 || Train Loss : 0.0031 (0.3554) || Train Top 1-acc : 100.000% (88.012)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [5/10][70/85] || LR : 0.00004 || Train Loss : 0.5924 (0.3393) || Train Top 1-acc : 93.750% (89.261)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [5/10][80/85] || LR : 0.00004 || Train Loss : 0.0027 (0.3399) || Train Top 1-acc : 100.000% (89.275)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55622089aca94ffab3d0323fb7b0de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10] || Val Loss : 0.0485 || Val Top 1-acc : 98.824% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed0754d11ca44268c9a8ec9e932e32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10][0/85] || LR : 0.00004 || Train Loss : 0.0060 (0.0060) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][10/85] || LR : 0.00003 || Train Loss : 0.6237 (0.1738) || Train Top 1-acc : 93.750% (95.455)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][20/85] || LR : 0.00003 || Train Loss : 0.8690 (0.2624) || Train Top 1-acc : 81.250% (94.345)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][30/85] || LR : 0.00003 || Train Loss : 0.7609 (0.3277) || Train Top 1-acc : 87.500% (92.944)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][40/85] || LR : 0.00003 || Train Loss : 0.3789 (0.3237) || Train Top 1-acc : 100.000% (92.530)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][50/85] || LR : 0.00002 || Train Loss : 0.0037 (0.3117) || Train Top 1-acc : 100.000% (92.402)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [6/10][60/85] || LR : 0.00002 || Train Loss : 0.4470 (0.3068) || Train Top 1-acc : 100.000% (93.648)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [6/10][70/85] || LR : 0.00002 || Train Loss : 0.7470 (0.3078) || Train Top 1-acc : 100.000% (93.398)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [6/10][80/85] || LR : 0.00002 || Train Loss : 0.0084 (0.3012) || Train Top 1-acc : 100.000% (93.673)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4144b7659d43409fd0ea9620ae83dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10] || Val Loss : 0.0286 || Val Top 1-acc : 98.824% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9de74e2ad94c7194977a548bec89ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10][0/85] || LR : 0.00002 || Train Loss : 0.0056 (0.0056) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][10/85] || LR : 0.00001 || Train Loss : 0.2165 (0.2785) || Train Top 1-acc : 100.000% (92.045)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][20/85] || LR : 0.00001 || Train Loss : 0.4463 (0.3574) || Train Top 1-acc : 100.000% (87.202)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][30/85] || LR : 0.00001 || Train Loss : 0.5680 (0.4040) || Train Top 1-acc : 87.500% (86.089)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][40/85] || LR : 0.00001 || Train Loss : 0.6585 (0.4326) || Train Top 1-acc : 50.000% (81.402)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][50/85] || LR : 0.00001 || Train Loss : 0.0033 (0.4182) || Train Top 1-acc : 100.000% (82.353)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][60/85] || LR : 0.00001 || Train Loss : 0.4754 (0.4248) || Train Top 1-acc : 100.000% (82.480)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][70/85] || LR : 0.00001 || Train Loss : 0.0022 (0.3955) || Train Top 1-acc : 100.000% (83.275)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][80/85] || LR : 0.00002 || Train Loss : 0.1527 (0.3748) || Train Top 1-acc : 100.000% (84.799)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6f8dc9fe13410ba5b36e8bd35c5b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10] || Val Loss : 0.0241 || Val Top 1-acc : 98.529% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c333a825977c4d18b0ff4e93a3169649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10][0/85] || LR : 0.00002 || Train Loss : 0.7053 (0.7053) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][10/85] || LR : 0.00002 || Train Loss : 0.0123 (0.4296) || Train Top 1-acc : 100.000% (88.068)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][20/85] || LR : 0.00002 || Train Loss : 0.5860 (0.3488) || Train Top 1-acc : 56.250% (89.583)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][30/85] || LR : 0.00002 || Train Loss : 0.0035 (0.2884) || Train Top 1-acc : 100.000% (92.742)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][40/85] || LR : 0.00002 || Train Loss : 0.0017 (0.2458) || Train Top 1-acc : 100.000% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][50/85] || LR : 0.00002 || Train Loss : 0.6352 (0.2529) || Train Top 1-acc : 25.000% (92.157)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][60/85] || LR : 0.00002 || Train Loss : 0.4637 (0.2591) || Train Top 1-acc : 93.750% (91.291)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][70/85] || LR : 0.00002 || Train Loss : 0.0913 (0.2458) || Train Top 1-acc : 100.000% (92.430)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][80/85] || LR : 0.00002 || Train Loss : 0.0029 (0.2675) || Train Top 1-acc : 100.000% (91.898)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330ccad8fa85409d8c2df9a3450bea11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10] || Val Loss : 0.0548 || Val Top 1-acc : 98.529% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f66b1a8c9f4d33838c58e4fbc86e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10][0/85] || LR : 0.00002 || Train Loss : 0.0085 (0.0085) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][10/85] || LR : 0.00002 || Train Loss : 0.0032 (0.2898) || Train Top 1-acc : 100.000% (93.182)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][20/85] || LR : 0.00002 || Train Loss : 0.0025 (0.2206) || Train Top 1-acc : 100.000% (96.131)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][30/85] || LR : 0.00002 || Train Loss : 0.0021 (0.2624) || Train Top 1-acc : 100.000% (92.540)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][40/85] || LR : 0.00002 || Train Loss : 0.0024 (0.2308) || Train Top 1-acc : 100.000% (93.902)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][50/85] || LR : 0.00002 || Train Loss : 0.0037 (0.2124) || Train Top 1-acc : 100.000% (94.240)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][60/85] || LR : 0.00002 || Train Loss : 0.6163 (0.2243) || Train Top 1-acc : 81.250% (94.570)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][70/85] || LR : 0.00002 || Train Loss : 0.5209 (0.2377) || Train Top 1-acc : 100.000% (94.190)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][80/85] || LR : 0.00001 || Train Loss : 0.0028 (0.2328) || Train Top 1-acc : 100.000% (93.981)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e689548ed5b74852977ce89b0fa6eb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10] || Val Loss : 0.0499 || Val Top 1-acc : 98.824% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c65b4c61ae34dda80f2faf4308b846d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10][0/85] || LR : 0.00001 || Train Loss : 0.0012 (0.0012) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][10/85] || LR : 0.00001 || Train Loss : 0.4145 (0.2699) || Train Top 1-acc : 100.000% (97.727)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][20/85] || LR : 0.00001 || Train Loss : 0.0012 (0.2629) || Train Top 1-acc : 100.000% (97.619)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][30/85] || LR : 0.00001 || Train Loss : 0.5747 (0.2955) || Train Top 1-acc : 100.000% (91.532)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][40/85] || LR : 0.00001 || Train Loss : 0.0017 (0.2580) || Train Top 1-acc : 100.000% (91.311)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [10/10][50/85] || LR : 0.00001 || Train Loss : 0.7088 (0.2563) || Train Top 1-acc : 43.750% (89.583)% || Train Top 5-acc : 100.000% (99.755)%\n",
      "Epoch : [10/10][60/85] || LR : 0.00001 || Train Loss : 0.6859 (0.2471) || Train Top 1-acc : 62.500% (90.369)% || Train Top 5-acc : 100.000% (99.795)%\n",
      "Epoch : [10/10][70/85] || LR : 0.00001 || Train Loss : 0.6162 (0.2428) || Train Top 1-acc : 87.500% (90.933)% || Train Top 5-acc : 100.000% (99.824)%\n",
      "Epoch : [10/10][80/85] || LR : 0.00001 || Train Loss : 0.0065 (0.2444) || Train Top 1-acc : 100.000% (91.127)% || Train Top 5-acc : 100.000% (99.846)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedc514143764ff38dce9949230c205d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10] || Val Loss : 0.0379 || Val Top 1-acc : 98.824% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============2-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b8136a57564242b912fa093080e877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10][0/85] || LR : 0.00001 || Train Loss : 1.9786 (1.9786) || Train Top 1-acc : 18.750% (18.750)% || Train Top 5-acc : 75.000% (75.000)%\n",
      "Epoch : [1/10][10/85] || LR : 0.00003 || Train Loss : 1.9056 (1.9197) || Train Top 1-acc : 12.500% (18.750)% || Train Top 5-acc : 68.750% (81.818)%\n",
      "Epoch : [1/10][20/85] || LR : 0.00004 || Train Loss : 1.3824 (1.7464) || Train Top 1-acc : 50.000% (31.845)% || Train Top 5-acc : 93.750% (87.500)%\n",
      "Epoch : [1/10][30/85] || LR : 0.00006 || Train Loss : 0.7627 (1.5567) || Train Top 1-acc : 81.250% (41.935)% || Train Top 5-acc : 100.000% (90.121)%\n",
      "Epoch : [1/10][40/85] || LR : 0.00008 || Train Loss : 0.7342 (1.3341) || Train Top 1-acc : 100.000% (52.744)% || Train Top 5-acc : 100.000% (92.378)%\n",
      "Epoch : [1/10][50/85] || LR : 0.00009 || Train Loss : 0.7819 (1.2193) || Train Top 1-acc : 81.250% (58.211)% || Train Top 5-acc : 100.000% (93.505)%\n",
      "Epoch : [1/10][60/85] || LR : 0.00010 || Train Loss : 0.9304 (1.1261) || Train Top 1-acc : 87.500% (63.115)% || Train Top 5-acc : 100.000% (94.570)%\n",
      "Epoch : [1/10][70/85] || LR : 0.00010 || Train Loss : 1.1189 (1.0639) || Train Top 1-acc : 68.750% (65.493)% || Train Top 5-acc : 100.000% (95.335)%\n",
      "Epoch : [1/10][80/85] || LR : 0.00010 || Train Loss : 0.5482 (1.0153) || Train Top 1-acc : 87.500% (67.515)% || Train Top 5-acc : 100.000% (95.756)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cd33bce97a43adb1c85fd61a48f8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10] || Val Loss : 0.1106 || Val Top 1-acc : 97.647% || Val Top 5-acc : 99.412%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3537e91b4f74d02b37f9fbcc12b84e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10][0/85] || LR : 0.00010 || Train Loss : 1.0929 (1.0929) || Train Top 1-acc : 75.000% (75.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/10][10/85] || LR : 0.00009 || Train Loss : 0.9855 (0.5546) || Train Top 1-acc : 100.000% (86.364)% || Train Top 5-acc : 100.000% (98.295)%\n",
      "Epoch : [2/10][20/85] || LR : 0.00009 || Train Loss : 0.0425 (0.4892) || Train Top 1-acc : 100.000% (86.607)% || Train Top 5-acc : 100.000% (98.810)%\n",
      "Epoch : [2/10][30/85] || LR : 0.00009 || Train Loss : 0.4465 (0.4609) || Train Top 1-acc : 100.000% (87.903)% || Train Top 5-acc : 100.000% (99.194)%\n",
      "Epoch : [2/10][40/85] || LR : 0.00008 || Train Loss : 0.1961 (0.4454) || Train Top 1-acc : 93.750% (85.366)% || Train Top 5-acc : 100.000% (99.238)%\n",
      "Epoch : [2/10][50/85] || LR : 0.00008 || Train Loss : 0.3380 (0.4155) || Train Top 1-acc : 87.500% (84.926)% || Train Top 5-acc : 100.000% (99.265)%\n",
      "Epoch : [2/10][60/85] || LR : 0.00007 || Train Loss : 0.0853 (0.4314) || Train Top 1-acc : 100.000% (84.324)% || Train Top 5-acc : 100.000% (99.385)%\n",
      "Epoch : [2/10][70/85] || LR : 0.00006 || Train Loss : 0.8239 (0.4433) || Train Top 1-acc : 87.500% (84.683)% || Train Top 5-acc : 100.000% (99.384)%\n",
      "Epoch : [2/10][80/85] || LR : 0.00006 || Train Loss : 0.7969 (0.4773) || Train Top 1-acc : 87.500% (84.491)% || Train Top 5-acc : 100.000% (99.383)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba0681a73234caf96742130398985e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10] || Val Loss : 0.0584 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9083f72d54a41318f8674314e714589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10][0/85] || LR : 0.00005 || Train Loss : 0.0847 (0.0847) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][10/85] || LR : 0.00005 || Train Loss : 0.0401 (0.4712) || Train Top 1-acc : 100.000% (78.409)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][20/85] || LR : 0.00004 || Train Loss : 0.0320 (0.3945) || Train Top 1-acc : 100.000% (79.762)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [3/10][30/85] || LR : 0.00004 || Train Loss : 0.0384 (0.4485) || Train Top 1-acc : 100.000% (76.613)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [3/10][40/85] || LR : 0.00003 || Train Loss : 0.2413 (0.4236) || Train Top 1-acc : 100.000% (80.793)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [3/10][50/85] || LR : 0.00003 || Train Loss : 0.0809 (0.3980) || Train Top 1-acc : 93.750% (83.088)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [3/10][60/85] || LR : 0.00002 || Train Loss : 0.0139 (0.3604) || Train Top 1-acc : 100.000% (85.143)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [3/10][70/85] || LR : 0.00002 || Train Loss : 0.0348 (0.3448) || Train Top 1-acc : 100.000% (86.180)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [3/10][80/85] || LR : 0.00001 || Train Loss : 0.0095 (0.3409) || Train Top 1-acc : 100.000% (86.343)% || Train Top 5-acc : 100.000% (99.691)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9269a7252514479eac34f34ddc454910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10] || Val Loss : 0.0292 || Val Top 1-acc : 99.118% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7948974a250b46968fedf493043ea658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10][0/85] || LR : 0.00001 || Train Loss : 0.0142 (0.0142) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][10/85] || LR : 0.00001 || Train Loss : 0.7210 (0.1531) || Train Top 1-acc : 68.750% (92.045)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][20/85] || LR : 0.00001 || Train Loss : 0.0117 (0.1085) || Train Top 1-acc : 100.000% (94.940)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][30/85] || LR : 0.00001 || Train Loss : 0.6184 (0.1680) || Train Top 1-acc : 43.750% (93.548)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][40/85] || LR : 0.00002 || Train Loss : 0.6395 (0.2423) || Train Top 1-acc : 93.750% (93.598)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][50/85] || LR : 0.00003 || Train Loss : 0.0177 (0.2327) || Train Top 1-acc : 100.000% (94.363)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [4/10][60/85] || LR : 0.00003 || Train Loss : 0.0082 (0.2169) || Train Top 1-acc : 100.000% (94.365)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [4/10][70/85] || LR : 0.00004 || Train Loss : 0.0111 (0.2166) || Train Top 1-acc : 100.000% (94.190)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [4/10][80/85] || LR : 0.00005 || Train Loss : 0.4796 (0.2176) || Train Top 1-acc : 93.750% (93.827)% || Train Top 5-acc : 100.000% (99.846)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106cb7d18ba14c5dbee8b1a61e45ce05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10] || Val Loss : 0.0124 || Val Top 1-acc : 100.000% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04d033bbe9f4a4580e0d0d737f0c7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10][0/85] || LR : 0.00005 || Train Loss : 0.4371 (0.4371) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][10/85] || LR : 0.00005 || Train Loss : 0.0152 (0.5655) || Train Top 1-acc : 100.000% (78.409)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][20/85] || LR : 0.00005 || Train Loss : 0.0176 (0.3995) || Train Top 1-acc : 100.000% (87.202)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][30/85] || LR : 0.00005 || Train Loss : 0.0067 (0.3112) || Train Top 1-acc : 100.000% (90.524)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][40/85] || LR : 0.00005 || Train Loss : 0.8374 (0.2774) || Train Top 1-acc : 93.750% (91.921)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][50/85] || LR : 0.00005 || Train Loss : 0.2836 (0.2649) || Train Top 1-acc : 100.000% (92.525)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][60/85] || LR : 0.00004 || Train Loss : 0.0054 (0.2688) || Train Top 1-acc : 100.000% (90.881)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][70/85] || LR : 0.00004 || Train Loss : 0.0297 (0.2616) || Train Top 1-acc : 100.000% (91.813)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][80/85] || LR : 0.00004 || Train Loss : 0.6366 (0.2890) || Train Top 1-acc : 87.500% (90.818)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d372e4c3b5c6410eb7cfa671cac5e77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10] || Val Loss : 0.0240 || Val Top 1-acc : 99.118% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b405a4aab990478f955486da20ff1d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10][0/85] || LR : 0.00004 || Train Loss : 0.0070 (0.0070) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][10/85] || LR : 0.00003 || Train Loss : 0.0140 (0.2751) || Train Top 1-acc : 100.000% (89.205)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][20/85] || LR : 0.00003 || Train Loss : 0.8425 (0.3024) || Train Top 1-acc : 18.750% (87.202)% || Train Top 5-acc : 93.750% (99.702)%\n",
      "Epoch : [6/10][30/85] || LR : 0.00003 || Train Loss : 0.0099 (0.2850) || Train Top 1-acc : 100.000% (86.290)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [6/10][40/85] || LR : 0.00003 || Train Loss : 0.7025 (0.2905) || Train Top 1-acc : 75.000% (85.213)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [6/10][50/85] || LR : 0.00002 || Train Loss : 0.8478 (0.2985) || Train Top 1-acc : 81.250% (87.255)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [6/10][60/85] || LR : 0.00002 || Train Loss : 0.3189 (0.3177) || Train Top 1-acc : 100.000% (86.988)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [6/10][70/85] || LR : 0.00002 || Train Loss : 0.0085 (0.2965) || Train Top 1-acc : 100.000% (88.028)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [6/10][80/85] || LR : 0.00002 || Train Loss : 0.0053 (0.2851) || Train Top 1-acc : 100.000% (89.352)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ddfdcfb46d4226972902f95d8f6930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10] || Val Loss : 0.0096 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5affdd38a429464d834e6698ca86b235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10][0/85] || LR : 0.00002 || Train Loss : 0.8451 (0.8451) || Train Top 1-acc : 68.750% (68.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][10/85] || LR : 0.00001 || Train Loss : 0.3970 (0.1916) || Train Top 1-acc : 93.750% (96.591)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][20/85] || LR : 0.00001 || Train Loss : 0.4457 (0.2410) || Train Top 1-acc : 93.750% (91.964)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][30/85] || LR : 0.00001 || Train Loss : 0.6965 (0.2587) || Train Top 1-acc : 93.750% (94.153)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][40/85] || LR : 0.00001 || Train Loss : 0.7570 (0.3079) || Train Top 1-acc : 93.750% (90.244)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][50/85] || LR : 0.00001 || Train Loss : 0.0028 (0.3068) || Train Top 1-acc : 100.000% (88.725)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [7/10][60/85] || LR : 0.00001 || Train Loss : 0.0070 (0.2952) || Train Top 1-acc : 100.000% (90.471)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [7/10][70/85] || LR : 0.00001 || Train Loss : 0.6754 (0.3054) || Train Top 1-acc : 100.000% (89.789)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [7/10][80/85] || LR : 0.00002 || Train Loss : 0.0094 (0.2912) || Train Top 1-acc : 100.000% (90.664)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703d364fc06b4836b3a7b0c4e1cbe752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10] || Val Loss : 0.0050 || Val Top 1-acc : 100.000% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116cbd8ffdab430790057935954587ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10][0/85] || LR : 0.00002 || Train Loss : 0.7817 (0.7817) || Train Top 1-acc : 81.250% (81.250)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][10/85] || LR : 0.00002 || Train Loss : 0.7176 (0.4617) || Train Top 1-acc : 62.500% (84.659)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][20/85] || LR : 0.00002 || Train Loss : 0.8492 (0.4741) || Train Top 1-acc : 37.500% (80.655)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [8/10][30/85] || LR : 0.00002 || Train Loss : 0.5736 (0.4226) || Train Top 1-acc : 100.000% (83.871)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [8/10][40/85] || LR : 0.00002 || Train Loss : 0.4147 (0.4164) || Train Top 1-acc : 100.000% (84.909)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [8/10][50/85] || LR : 0.00002 || Train Loss : 0.0020 (0.3762) || Train Top 1-acc : 100.000% (86.642)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [8/10][60/85] || LR : 0.00002 || Train Loss : 0.6746 (0.3975) || Train Top 1-acc : 100.000% (87.500)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [8/10][70/85] || LR : 0.00002 || Train Loss : 0.5722 (0.3860) || Train Top 1-acc : 50.000% (87.676)% || Train Top 5-acc : 93.750% (99.648)%\n",
      "Epoch : [8/10][80/85] || LR : 0.00002 || Train Loss : 0.7933 (0.3881) || Train Top 1-acc : 87.500% (87.114)% || Train Top 5-acc : 100.000% (99.691)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f67c7852ba4d8e8d3309ebeb43e6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10] || Val Loss : 0.0110 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcab960c67d42eb98d062c10b42e921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10][0/85] || LR : 0.00002 || Train Loss : 0.0027 (0.0027) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][10/85] || LR : 0.00002 || Train Loss : 0.0083 (0.0644) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][20/85] || LR : 0.00002 || Train Loss : 0.0031 (0.1934) || Train Top 1-acc : 100.000% (91.964)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][30/85] || LR : 0.00002 || Train Loss : 0.6657 (0.2242) || Train Top 1-acc : 37.500% (90.726)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][40/85] || LR : 0.00002 || Train Loss : 0.0052 (0.2519) || Train Top 1-acc : 100.000% (89.787)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][50/85] || LR : 0.00002 || Train Loss : 0.0018 (0.2451) || Train Top 1-acc : 100.000% (89.216)% || Train Top 5-acc : 100.000% (99.755)%\n",
      "Epoch : [9/10][60/85] || LR : 0.00002 || Train Loss : 0.0038 (0.2543) || Train Top 1-acc : 100.000% (89.754)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [9/10][70/85] || LR : 0.00002 || Train Loss : 0.0036 (0.2378) || Train Top 1-acc : 100.000% (90.581)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [9/10][80/85] || LR : 0.00001 || Train Loss : 0.0073 (0.2398) || Train Top 1-acc : 100.000% (91.204)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2c6d3cbbe64d4b93ce566b2f14407e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10] || Val Loss : 0.0074 || Val Top 1-acc : 100.000% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e35ff66633c4aa6aec8970c7c2dd525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10][0/85] || LR : 0.00001 || Train Loss : 0.8033 (0.8033) || Train Top 1-acc : 18.750% (18.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][10/85] || LR : 0.00001 || Train Loss : 0.0049 (0.3229) || Train Top 1-acc : 100.000% (83.523)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [10/10][20/85] || LR : 0.00001 || Train Loss : 0.4185 (0.2718) || Train Top 1-acc : 87.500% (84.821)% || Train Top 5-acc : 100.000% (99.702)%\n",
      "Epoch : [10/10][30/85] || LR : 0.00001 || Train Loss : 0.0085 (0.2215) || Train Top 1-acc : 100.000% (89.113)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [10/10][40/85] || LR : 0.00001 || Train Loss : 0.0023 (0.2758) || Train Top 1-acc : 100.000% (89.177)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [10/10][50/85] || LR : 0.00001 || Train Loss : 0.4751 (0.2923) || Train Top 1-acc : 100.000% (88.603)% || Train Top 5-acc : 100.000% (99.755)%\n",
      "Epoch : [10/10][60/85] || LR : 0.00001 || Train Loss : 0.0058 (0.2990) || Train Top 1-acc : 100.000% (87.295)% || Train Top 5-acc : 100.000% (99.795)%\n",
      "Epoch : [10/10][70/85] || LR : 0.00001 || Train Loss : 0.0025 (0.2934) || Train Top 1-acc : 100.000% (88.556)% || Train Top 5-acc : 100.000% (99.824)%\n",
      "Epoch : [10/10][80/85] || LR : 0.00001 || Train Loss : 0.0030 (0.2960) || Train Top 1-acc : 100.000% (89.043)% || Train Top 5-acc : 100.000% (99.846)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2257d76afac4ff4924dbea342d4e44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10] || Val Loss : 0.0043 || Val Top 1-acc : 100.000% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============3-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b4f290fd6e4921be90dc5b854369c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10][0/85] || LR : 0.00001 || Train Loss : 2.0720 (2.0720) || Train Top 1-acc : 12.500% (12.500)% || Train Top 5-acc : 62.500% (62.500)%\n",
      "Epoch : [1/10][10/85] || LR : 0.00003 || Train Loss : 1.7776 (1.9316) || Train Top 1-acc : 43.750% (23.864)% || Train Top 5-acc : 75.000% (76.136)%\n",
      "Epoch : [1/10][20/85] || LR : 0.00004 || Train Loss : 1.4177 (1.8146) || Train Top 1-acc : 50.000% (29.762)% || Train Top 5-acc : 100.000% (82.738)%\n",
      "Epoch : [1/10][30/85] || LR : 0.00006 || Train Loss : 1.5192 (1.6751) || Train Top 1-acc : 37.500% (36.895)% || Train Top 5-acc : 100.000% (86.694)%\n",
      "Epoch : [1/10][40/85] || LR : 0.00008 || Train Loss : 0.7066 (1.4569) || Train Top 1-acc : 87.500% (48.018)% || Train Top 5-acc : 100.000% (89.634)%\n",
      "Epoch : [1/10][50/85] || LR : 0.00009 || Train Loss : 0.8877 (1.3557) || Train Top 1-acc : 75.000% (52.819)% || Train Top 5-acc : 93.750% (91.299)%\n",
      "Epoch : [1/10][60/85] || LR : 0.00010 || Train Loss : 1.1762 (1.2324) || Train Top 1-acc : 75.000% (57.582)% || Train Top 5-acc : 100.000% (92.623)%\n",
      "Epoch : [1/10][70/85] || LR : 0.00010 || Train Loss : 0.2511 (1.1340) || Train Top 1-acc : 93.750% (61.180)% || Train Top 5-acc : 100.000% (93.134)%\n",
      "Epoch : [1/10][80/85] || LR : 0.00010 || Train Loss : 0.0398 (1.0670) || Train Top 1-acc : 100.000% (64.275)% || Train Top 5-acc : 100.000% (93.981)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d979dbaf67754cdca5c362d6ebc26831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10] || Val Loss : 0.1052 || Val Top 1-acc : 97.353% || Val Top 5-acc : 99.706%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ac3c5a960f41c4b0cb9ccff23edfeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10][0/85] || LR : 0.00010 || Train Loss : 0.1522 (0.1522) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/10][10/85] || LR : 0.00009 || Train Loss : 0.7374 (0.5063) || Train Top 1-acc : 100.000% (88.636)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [2/10][20/85] || LR : 0.00009 || Train Loss : 0.0710 (0.4124) || Train Top 1-acc : 100.000% (88.393)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [2/10][30/85] || LR : 0.00009 || Train Loss : 0.0451 (0.4122) || Train Top 1-acc : 100.000% (86.290)% || Train Top 5-acc : 100.000% (99.597)%\n",
      "Epoch : [2/10][40/85] || LR : 0.00008 || Train Loss : 0.9314 (0.4282) || Train Top 1-acc : 62.500% (85.366)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [2/10][50/85] || LR : 0.00008 || Train Loss : 0.0468 (0.4101) || Train Top 1-acc : 100.000% (85.784)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [2/10][60/85] || LR : 0.00007 || Train Loss : 0.7474 (0.4185) || Train Top 1-acc : 93.750% (86.475)% || Train Top 5-acc : 100.000% (99.590)%\n",
      "Epoch : [2/10][70/85] || LR : 0.00006 || Train Loss : 0.0288 (0.4013) || Train Top 1-acc : 100.000% (87.764)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [2/10][80/85] || LR : 0.00006 || Train Loss : 0.0481 (0.4107) || Train Top 1-acc : 100.000% (87.346)% || Train Top 5-acc : 100.000% (99.614)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aef67abcf0d447399dd7565fed8e1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10] || Val Loss : 0.0466 || Val Top 1-acc : 98.824% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb880379f3d4bb58e3fc68a2c5e50f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10][0/85] || LR : 0.00005 || Train Loss : 0.0975 (0.0975) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][10/85] || LR : 0.00005 || Train Loss : 0.6538 (0.3331) || Train Top 1-acc : 93.750% (97.159)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][20/85] || LR : 0.00004 || Train Loss : 0.0456 (0.3037) || Train Top 1-acc : 100.000% (97.917)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][30/85] || LR : 0.00004 || Train Loss : 0.8460 (0.3477) || Train Top 1-acc : 68.750% (94.556)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][40/85] || LR : 0.00003 || Train Loss : 0.2994 (0.3534) || Train Top 1-acc : 93.750% (92.073)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][50/85] || LR : 0.00003 || Train Loss : 0.0195 (0.3358) || Train Top 1-acc : 100.000% (92.034)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [3/10][60/85] || LR : 0.00002 || Train Loss : 0.0105 (0.3068) || Train Top 1-acc : 100.000% (92.623)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [3/10][70/85] || LR : 0.00002 || Train Loss : 0.0128 (0.3065) || Train Top 1-acc : 100.000% (92.694)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [3/10][80/85] || LR : 0.00001 || Train Loss : 0.3932 (0.3081) || Train Top 1-acc : 93.750% (92.901)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c730546c98ca424cbfa6f5705ab4bbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10] || Val Loss : 0.0331 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a207413e0d06493a858efcd99cbd5cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10][0/85] || LR : 0.00001 || Train Loss : 0.5570 (0.5570) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][10/85] || LR : 0.00001 || Train Loss : 0.3258 (0.3006) || Train Top 1-acc : 100.000% (94.318)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][20/85] || LR : 0.00001 || Train Loss : 0.5734 (0.3007) || Train Top 1-acc : 100.000% (90.774)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][30/85] || LR : 0.00001 || Train Loss : 0.0303 (0.3164) || Train Top 1-acc : 100.000% (89.718)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [4/10][40/85] || LR : 0.00002 || Train Loss : 0.0232 (0.3054) || Train Top 1-acc : 100.000% (91.768)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [4/10][50/85] || LR : 0.00003 || Train Loss : 0.0116 (0.3024) || Train Top 1-acc : 100.000% (92.157)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [4/10][60/85] || LR : 0.00003 || Train Loss : 0.8345 (0.3167) || Train Top 1-acc : 87.500% (91.701)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [4/10][70/85] || LR : 0.00004 || Train Loss : 0.0108 (0.3137) || Train Top 1-acc : 100.000% (90.845)% || Train Top 5-acc : 100.000% (99.824)%\n",
      "Epoch : [4/10][80/85] || LR : 0.00005 || Train Loss : 0.0077 (0.3195) || Train Top 1-acc : 100.000% (89.429)% || Train Top 5-acc : 100.000% (99.846)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4761813e7ecb4656a796edce42d57cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10] || Val Loss : 0.0223 || Val Top 1-acc : 99.118% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172c07b34f8a438ab70a0773b3c31c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10][0/85] || LR : 0.00005 || Train Loss : 0.0156 (0.0156) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][10/85] || LR : 0.00005 || Train Loss : 0.0072 (0.2611) || Train Top 1-acc : 100.000% (84.659)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][20/85] || LR : 0.00005 || Train Loss : 0.0092 (0.1958) || Train Top 1-acc : 100.000% (89.286)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][30/85] || LR : 0.00005 || Train Loss : 0.0100 (0.1986) || Train Top 1-acc : 100.000% (92.742)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][40/85] || LR : 0.00005 || Train Loss : 0.6878 (0.2660) || Train Top 1-acc : 100.000% (92.226)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][50/85] || LR : 0.00005 || Train Loss : 0.0070 (0.2976) || Train Top 1-acc : 100.000% (90.441)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][60/85] || LR : 0.00004 || Train Loss : 0.9078 (0.3341) || Train Top 1-acc : 81.250% (89.139)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][70/85] || LR : 0.00004 || Train Loss : 0.6196 (0.3450) || Train Top 1-acc : 81.250% (88.556)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][80/85] || LR : 0.00004 || Train Loss : 0.0594 (0.3470) || Train Top 1-acc : 100.000% (88.580)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c67f34d14d4c5bbf8a8e1131625d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10] || Val Loss : 0.0287 || Val Top 1-acc : 99.118% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11caa126cf6747e182a4e0ba56665ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10][0/85] || LR : 0.00004 || Train Loss : 0.5246 (0.5246) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][10/85] || LR : 0.00003 || Train Loss : 0.6923 (0.3866) || Train Top 1-acc : 87.500% (89.205)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][20/85] || LR : 0.00003 || Train Loss : 0.5975 (0.4660) || Train Top 1-acc : 62.500% (83.631)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][30/85] || LR : 0.00003 || Train Loss : 0.7972 (0.4186) || Train Top 1-acc : 18.750% (83.065)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][40/85] || LR : 0.00003 || Train Loss : 0.0336 (0.4082) || Train Top 1-acc : 100.000% (83.994)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][50/85] || LR : 0.00002 || Train Loss : 0.0021 (0.3904) || Train Top 1-acc : 100.000% (86.887)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][60/85] || LR : 0.00002 || Train Loss : 0.0051 (0.3658) || Train Top 1-acc : 100.000% (88.320)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [6/10][70/85] || LR : 0.00002 || Train Loss : 0.5820 (0.3447) || Train Top 1-acc : 100.000% (89.525)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [6/10][80/85] || LR : 0.00002 || Train Loss : 0.0028 (0.3448) || Train Top 1-acc : 100.000% (89.275)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0cfcda649543a29a7c2e7723e3926c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10] || Val Loss : 0.0236 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f4d2c95ae5491d9f330c73622edc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10][0/85] || LR : 0.00002 || Train Loss : 0.7110 (0.7110) || Train Top 1-acc : 87.500% (87.500)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][10/85] || LR : 0.00001 || Train Loss : 0.9598 (0.4299) || Train Top 1-acc : 25.000% (80.682)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][20/85] || LR : 0.00001 || Train Loss : 0.5731 (0.3490) || Train Top 1-acc : 100.000% (89.286)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][30/85] || LR : 0.00001 || Train Loss : 0.0206 (0.3777) || Train Top 1-acc : 100.000% (87.702)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [7/10][40/85] || LR : 0.00001 || Train Loss : 0.0045 (0.3647) || Train Top 1-acc : 100.000% (89.177)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [7/10][50/85] || LR : 0.00001 || Train Loss : 0.5658 (0.3217) || Train Top 1-acc : 62.500% (90.074)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [7/10][60/85] || LR : 0.00001 || Train Loss : 0.0022 (0.3149) || Train Top 1-acc : 100.000% (90.164)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [7/10][70/85] || LR : 0.00001 || Train Loss : 0.5986 (0.3160) || Train Top 1-acc : 37.500% (88.556)% || Train Top 5-acc : 93.750% (99.736)%\n",
      "Epoch : [7/10][80/85] || LR : 0.00002 || Train Loss : 0.0064 (0.3103) || Train Top 1-acc : 100.000% (89.583)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f285ea915f4e7897c91ae06b38e20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10] || Val Loss : 0.0229 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba87c51dadba486bbb5ddfcc2baf9547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10][0/85] || LR : 0.00002 || Train Loss : 0.0126 (0.0126) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][10/85] || LR : 0.00002 || Train Loss : 0.0046 (0.3209) || Train Top 1-acc : 100.000% (84.659)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][20/85] || LR : 0.00002 || Train Loss : 0.0030 (0.2900) || Train Top 1-acc : 100.000% (87.500)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][30/85] || LR : 0.00002 || Train Loss : 0.0098 (0.2692) || Train Top 1-acc : 100.000% (91.331)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][40/85] || LR : 0.00002 || Train Loss : 0.0039 (0.2477) || Train Top 1-acc : 100.000% (92.530)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][50/85] || LR : 0.00002 || Train Loss : 0.8142 (0.2741) || Train Top 1-acc : 62.500% (91.667)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][60/85] || LR : 0.00002 || Train Loss : 0.6055 (0.2918) || Train Top 1-acc : 93.750% (89.447)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][70/85] || LR : 0.00002 || Train Loss : 0.6436 (0.3183) || Train Top 1-acc : 100.000% (88.644)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][80/85] || LR : 0.00002 || Train Loss : 0.0013 (0.2972) || Train Top 1-acc : 100.000% (89.043)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c550a4b4cf45278c9c430b40b956ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10] || Val Loss : 0.0184 || Val Top 1-acc : 99.412% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3369dec388c04aa9bb59a55b8978a5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10][0/85] || LR : 0.00002 || Train Loss : 0.0027 (0.0027) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][10/85] || LR : 0.00002 || Train Loss : 0.5898 (0.2487) || Train Top 1-acc : 75.000% (89.205)% || Train Top 5-acc : 100.000% (98.295)%\n",
      "Epoch : [9/10][20/85] || LR : 0.00002 || Train Loss : 0.0021 (0.1797) || Train Top 1-acc : 100.000% (94.345)% || Train Top 5-acc : 100.000% (99.107)%\n",
      "Epoch : [9/10][30/85] || LR : 0.00002 || Train Loss : 0.0068 (0.2011) || Train Top 1-acc : 100.000% (94.758)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [9/10][40/85] || LR : 0.00002 || Train Loss : 0.3292 (0.2237) || Train Top 1-acc : 100.000% (95.122)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [9/10][50/85] || LR : 0.00002 || Train Loss : 0.0079 (0.2265) || Train Top 1-acc : 100.000% (93.995)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [9/10][60/85] || LR : 0.00002 || Train Loss : 0.0014 (0.2211) || Train Top 1-acc : 100.000% (93.852)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [9/10][70/85] || LR : 0.00002 || Train Loss : 0.7926 (0.2363) || Train Top 1-acc : 75.000% (93.046)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [9/10][80/85] || LR : 0.00001 || Train Loss : 0.6087 (0.2463) || Train Top 1-acc : 31.250% (92.901)% || Train Top 5-acc : 87.500% (99.537)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7698d432486e47219120fcd33523b366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10] || Val Loss : 0.0131 || Val Top 1-acc : 99.706% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a174d94253dd4e2bbeeaa736741615ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10][0/85] || LR : 0.00001 || Train Loss : 0.4328 (0.4328) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][10/85] || LR : 0.00001 || Train Loss : 0.6455 (0.4515) || Train Top 1-acc : 100.000% (88.068)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][20/85] || LR : 0.00001 || Train Loss : 0.2457 (0.3538) || Train Top 1-acc : 100.000% (89.583)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][30/85] || LR : 0.00001 || Train Loss : 0.0033 (0.2960) || Train Top 1-acc : 100.000% (90.726)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][40/85] || LR : 0.00001 || Train Loss : 0.5825 (0.3055) || Train Top 1-acc : 100.000% (90.244)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][50/85] || LR : 0.00001 || Train Loss : 0.6785 (0.3167) || Train Top 1-acc : 100.000% (91.544)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][60/85] || LR : 0.00001 || Train Loss : 0.5924 (0.3040) || Train Top 1-acc : 100.000% (92.316)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][70/85] || LR : 0.00001 || Train Loss : 0.0020 (0.2927) || Train Top 1-acc : 100.000% (92.870)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][80/85] || LR : 0.00001 || Train Loss : 0.5519 (0.2729) || Train Top 1-acc : 100.000% (92.824)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136e3f852f074f05ab93090f698ec39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10] || Val Loss : 0.0160 || Val Top 1-acc : 99.412% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============4-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d053667ad06417fac04253dd292eb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10][0/85] || LR : 0.00001 || Train Loss : 2.1108 (2.1108) || Train Top 1-acc : 0.000% (0.000)% || Train Top 5-acc : 62.500% (62.500)%\n",
      "Epoch : [1/10][10/85] || LR : 0.00003 || Train Loss : 1.8617 (1.8976) || Train Top 1-acc : 12.500% (15.909)% || Train Top 5-acc : 100.000% (79.545)%\n",
      "Epoch : [1/10][20/85] || LR : 0.00004 || Train Loss : 1.1728 (1.7297) || Train Top 1-acc : 62.500% (29.762)% || Train Top 5-acc : 100.000% (87.202)%\n",
      "Epoch : [1/10][30/85] || LR : 0.00006 || Train Loss : 1.0114 (1.5880) || Train Top 1-acc : 43.750% (37.702)% || Train Top 5-acc : 100.000% (89.516)%\n",
      "Epoch : [1/10][40/85] || LR : 0.00008 || Train Loss : 1.1918 (1.3777) || Train Top 1-acc : 87.500% (48.018)% || Train Top 5-acc : 93.750% (91.463)%\n",
      "Epoch : [1/10][50/85] || LR : 0.00009 || Train Loss : 0.3317 (1.1855) || Train Top 1-acc : 93.750% (55.147)% || Train Top 5-acc : 100.000% (92.770)%\n",
      "Epoch : [1/10][60/85] || LR : 0.00010 || Train Loss : 0.7014 (1.1024) || Train Top 1-acc : 93.750% (60.041)% || Train Top 5-acc : 100.000% (93.852)%\n",
      "Epoch : [1/10][70/85] || LR : 0.00010 || Train Loss : 1.0357 (1.0330) || Train Top 1-acc : 56.250% (62.500)% || Train Top 5-acc : 100.000% (94.630)%\n",
      "Epoch : [1/10][80/85] || LR : 0.00010 || Train Loss : 0.1170 (0.9727) || Train Top 1-acc : 93.750% (65.355)% || Train Top 5-acc : 100.000% (95.139)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c382e738ab44e4bbc1a50fa506a1a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10] || Val Loss : 0.1316 || Val Top 1-acc : 96.755% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85ff31b2c9647d59b64ac57a3c44a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10][0/85] || LR : 0.00010 || Train Loss : 0.9091 (0.9091) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/10][10/85] || LR : 0.00009 || Train Loss : 0.0604 (0.5182) || Train Top 1-acc : 100.000% (82.386)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [2/10][20/85] || LR : 0.00009 || Train Loss : 0.4621 (0.4736) || Train Top 1-acc : 87.500% (85.714)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [2/10][30/85] || LR : 0.00009 || Train Loss : 0.0275 (0.4028) || Train Top 1-acc : 100.000% (89.113)% || Train Top 5-acc : 100.000% (99.597)%\n",
      "Epoch : [2/10][40/85] || LR : 0.00008 || Train Loss : 0.1133 (0.3619) || Train Top 1-acc : 100.000% (90.549)% || Train Top 5-acc : 100.000% (99.695)%\n",
      "Epoch : [2/10][50/85] || LR : 0.00008 || Train Loss : 0.0364 (0.3784) || Train Top 1-acc : 100.000% (88.971)% || Train Top 5-acc : 100.000% (99.755)%\n",
      "Epoch : [2/10][60/85] || LR : 0.00007 || Train Loss : 0.0336 (0.3608) || Train Top 1-acc : 100.000% (90.164)% || Train Top 5-acc : 100.000% (99.795)%\n",
      "Epoch : [2/10][70/85] || LR : 0.00006 || Train Loss : 0.8431 (0.3535) || Train Top 1-acc : 81.250% (90.141)% || Train Top 5-acc : 100.000% (99.824)%\n",
      "Epoch : [2/10][80/85] || LR : 0.00006 || Train Loss : 1.1812 (0.3608) || Train Top 1-acc : 37.500% (89.429)% || Train Top 5-acc : 93.750% (99.691)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b12ec6575cc42c7b4f506ad4fac9092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10] || Val Loss : 0.1468 || Val Top 1-acc : 96.165% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f463c60e094ce8bad3c53c560425c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10][0/85] || LR : 0.00005 || Train Loss : 0.2246 (0.2246) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][10/85] || LR : 0.00005 || Train Loss : 0.9671 (0.2779) || Train Top 1-acc : 68.750% (94.318)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][20/85] || LR : 0.00004 || Train Loss : 0.0288 (0.2994) || Train Top 1-acc : 100.000% (91.964)% || Train Top 5-acc : 100.000% (99.107)%\n",
      "Epoch : [3/10][30/85] || LR : 0.00004 || Train Loss : 0.7963 (0.3208) || Train Top 1-acc : 75.000% (92.339)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [3/10][40/85] || LR : 0.00003 || Train Loss : 0.0200 (0.3825) || Train Top 1-acc : 100.000% (88.415)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [3/10][50/85] || LR : 0.00003 || Train Loss : 0.0376 (0.3615) || Train Top 1-acc : 100.000% (89.583)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [3/10][60/85] || LR : 0.00002 || Train Loss : 0.0171 (0.3721) || Train Top 1-acc : 100.000% (89.242)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [3/10][70/85] || LR : 0.00002 || Train Loss : 0.0067 (0.3339) || Train Top 1-acc : 100.000% (90.317)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [3/10][80/85] || LR : 0.00001 || Train Loss : 0.0069 (0.3072) || Train Top 1-acc : 100.000% (90.818)% || Train Top 5-acc : 100.000% (99.691)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952c508e217643959983b1cbf6b038f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10] || Val Loss : 0.0580 || Val Top 1-acc : 97.345% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad0eda495964b0eaff36f7cbf087cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10][0/85] || LR : 0.00001 || Train Loss : 0.5756 (0.5756) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][10/85] || LR : 0.00001 || Train Loss : 0.0418 (0.3361) || Train Top 1-acc : 100.000% (82.955)% || Train Top 5-acc : 100.000% (98.295)%\n",
      "Epoch : [4/10][20/85] || LR : 0.00001 || Train Loss : 0.6049 (0.3751) || Train Top 1-acc : 100.000% (84.524)% || Train Top 5-acc : 100.000% (99.107)%\n",
      "Epoch : [4/10][30/85] || LR : 0.00001 || Train Loss : 0.1730 (0.3705) || Train Top 1-acc : 93.750% (84.879)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [4/10][40/85] || LR : 0.00002 || Train Loss : 0.7159 (0.3748) || Train Top 1-acc : 100.000% (87.805)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [4/10][50/85] || LR : 0.00003 || Train Loss : 0.3958 (0.3576) || Train Top 1-acc : 100.000% (89.216)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [4/10][60/85] || LR : 0.00003 || Train Loss : 0.0115 (0.3394) || Train Top 1-acc : 100.000% (89.857)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [4/10][70/85] || LR : 0.00004 || Train Loss : 0.2760 (0.3272) || Train Top 1-acc : 100.000% (90.845)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [4/10][80/85] || LR : 0.00005 || Train Loss : 0.0097 (0.3161) || Train Top 1-acc : 100.000% (90.664)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2b529719bc4612a3f147eb6b446410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10] || Val Loss : 0.0969 || Val Top 1-acc : 97.050% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28036de2a79a496ab07b651b3620a253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10][0/85] || LR : 0.00005 || Train Loss : 0.2456 (0.2456) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][10/85] || LR : 0.00005 || Train Loss : 0.0148 (0.3081) || Train Top 1-acc : 100.000% (91.477)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][20/85] || LR : 0.00005 || Train Loss : 0.6745 (0.3977) || Train Top 1-acc : 93.750% (90.774)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][30/85] || LR : 0.00005 || Train Loss : 0.0173 (0.3700) || Train Top 1-acc : 100.000% (90.323)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][40/85] || LR : 0.00005 || Train Loss : 0.0148 (0.3435) || Train Top 1-acc : 100.000% (91.768)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][50/85] || LR : 0.00005 || Train Loss : 0.0073 (0.3391) || Train Top 1-acc : 100.000% (91.422)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][60/85] || LR : 0.00004 || Train Loss : 0.4713 (0.3340) || Train Top 1-acc : 100.000% (92.008)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [5/10][70/85] || LR : 0.00004 || Train Loss : 0.0109 (0.3454) || Train Top 1-acc : 100.000% (92.430)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [5/10][80/85] || LR : 0.00004 || Train Loss : 0.8212 (0.3591) || Train Top 1-acc : 87.500% (91.358)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b8cc9da5954c6681f316bf0292fbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10] || Val Loss : 0.0336 || Val Top 1-acc : 98.820% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03318c863cab43fca2e8bb183c0bbaff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10][0/85] || LR : 0.00004 || Train Loss : 0.3899 (0.3899) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][10/85] || LR : 0.00003 || Train Loss : 0.0154 (0.0537) || Train Top 1-acc : 100.000% (99.432)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][20/85] || LR : 0.00003 || Train Loss : 0.7629 (0.1997) || Train Top 1-acc : 93.750% (89.286)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [6/10][30/85] || LR : 0.00003 || Train Loss : 0.5958 (0.2350) || Train Top 1-acc : 87.500% (91.129)% || Train Top 5-acc : 100.000% (99.597)%\n",
      "Epoch : [6/10][40/85] || LR : 0.00003 || Train Loss : 0.0045 (0.2186) || Train Top 1-acc : 100.000% (92.073)% || Train Top 5-acc : 100.000% (99.695)%\n",
      "Epoch : [6/10][50/85] || LR : 0.00002 || Train Loss : 0.5276 (0.2654) || Train Top 1-acc : 93.750% (90.686)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [6/10][60/85] || LR : 0.00002 || Train Loss : 0.0084 (0.2493) || Train Top 1-acc : 100.000% (91.189)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [6/10][70/85] || LR : 0.00002 || Train Loss : 0.0057 (0.2545) || Train Top 1-acc : 100.000% (89.613)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [6/10][80/85] || LR : 0.00002 || Train Loss : 0.6041 (0.2553) || Train Top 1-acc : 62.500% (89.352)% || Train Top 5-acc : 100.000% (99.691)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5402dc589ed847c3a1500eb6507d6618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10] || Val Loss : 0.0320 || Val Top 1-acc : 98.230% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becc62eaf6c54101a30d66b94fb85d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10][0/85] || LR : 0.00002 || Train Loss : 0.5307 (0.5307) || Train Top 1-acc : 87.500% (87.500)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][10/85] || LR : 0.00001 || Train Loss : 0.0054 (0.3147) || Train Top 1-acc : 100.000% (91.477)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][20/85] || LR : 0.00001 || Train Loss : 0.0055 (0.2666) || Train Top 1-acc : 100.000% (93.452)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][30/85] || LR : 0.00001 || Train Loss : 0.0080 (0.2908) || Train Top 1-acc : 100.000% (89.315)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][40/85] || LR : 0.00001 || Train Loss : 0.0085 (0.2561) || Train Top 1-acc : 100.000% (90.244)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [7/10][50/85] || LR : 0.00001 || Train Loss : 0.6985 (0.2960) || Train Top 1-acc : 81.250% (87.132)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [7/10][60/85] || LR : 0.00001 || Train Loss : 0.0053 (0.3152) || Train Top 1-acc : 100.000% (85.246)% || Train Top 5-acc : 100.000% (99.795)%\n",
      "Epoch : [7/10][70/85] || LR : 0.00001 || Train Loss : 0.2425 (0.3452) || Train Top 1-acc : 100.000% (84.419)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [7/10][80/85] || LR : 0.00002 || Train Loss : 0.0069 (0.3274) || Train Top 1-acc : 100.000% (84.491)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4b17b2c70f4ecc82eb465ffd44f6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10] || Val Loss : 0.0270 || Val Top 1-acc : 99.410% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7a8c66f45b480792b4c1debcbf8073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10][0/85] || LR : 0.00002 || Train Loss : 0.4553 (0.4553) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][10/85] || LR : 0.00002 || Train Loss : 0.5086 (0.1545) || Train Top 1-acc : 93.750% (99.432)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][20/85] || LR : 0.00002 || Train Loss : 0.0089 (0.2241) || Train Top 1-acc : 100.000% (95.238)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][30/85] || LR : 0.00002 || Train Loss : 0.0119 (0.2344) || Train Top 1-acc : 100.000% (91.935)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][40/85] || LR : 0.00002 || Train Loss : 0.0201 (0.2248) || Train Top 1-acc : 100.000% (90.549)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][50/85] || LR : 0.00002 || Train Loss : 0.0034 (0.2730) || Train Top 1-acc : 100.000% (88.971)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][60/85] || LR : 0.00002 || Train Loss : 0.0028 (0.2727) || Train Top 1-acc : 100.000% (89.754)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][70/85] || LR : 0.00002 || Train Loss : 0.0142 (0.2914) || Train Top 1-acc : 100.000% (90.141)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][80/85] || LR : 0.00002 || Train Loss : 0.0028 (0.2728) || Train Top 1-acc : 100.000% (91.204)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0c40d2caff477995c0540b9619a44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10] || Val Loss : 0.0294 || Val Top 1-acc : 98.525% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2281c42112e544ef916fa759afa7060e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10][0/85] || LR : 0.00002 || Train Loss : 0.7818 (0.7818) || Train Top 1-acc : 75.000% (75.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][10/85] || LR : 0.00002 || Train Loss : 0.7282 (0.3394) || Train Top 1-acc : 68.750% (85.227)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][20/85] || LR : 0.00002 || Train Loss : 0.2990 (0.3756) || Train Top 1-acc : 100.000% (82.143)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [9/10][30/85] || LR : 0.00002 || Train Loss : 0.0026 (0.3406) || Train Top 1-acc : 100.000% (84.677)% || Train Top 5-acc : 100.000% (99.597)%\n",
      "Epoch : [9/10][40/85] || LR : 0.00002 || Train Loss : 0.0021 (0.2912) || Train Top 1-acc : 100.000% (88.262)% || Train Top 5-acc : 100.000% (99.695)%\n",
      "Epoch : [9/10][50/85] || LR : 0.00002 || Train Loss : 0.0030 (0.2494) || Train Top 1-acc : 100.000% (90.319)% || Train Top 5-acc : 100.000% (99.755)%\n",
      "Epoch : [9/10][60/85] || LR : 0.00002 || Train Loss : 0.7077 (0.2870) || Train Top 1-acc : 18.750% (90.164)% || Train Top 5-acc : 100.000% (99.795)%\n",
      "Epoch : [9/10][70/85] || LR : 0.00002 || Train Loss : 0.0023 (0.2583) || Train Top 1-acc : 100.000% (91.373)% || Train Top 5-acc : 100.000% (99.824)%\n",
      "Epoch : [9/10][80/85] || LR : 0.00001 || Train Loss : 0.6054 (0.2762) || Train Top 1-acc : 100.000% (90.664)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6162e4e37be2492ea2435333884fc454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10] || Val Loss : 0.0227 || Val Top 1-acc : 99.410% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c563f0fb28403f927f247d5ec50e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10][0/85] || LR : 0.00001 || Train Loss : 0.0028 (0.0028) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][10/85] || LR : 0.00001 || Train Loss : 0.2013 (0.3793) || Train Top 1-acc : 100.000% (98.295)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][20/85] || LR : 0.00001 || Train Loss : 0.6386 (0.4370) || Train Top 1-acc : 100.000% (91.071)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [10/10][30/85] || LR : 0.00001 || Train Loss : 0.0031 (0.3684) || Train Top 1-acc : 100.000% (93.347)% || Train Top 5-acc : 100.000% (99.597)%\n",
      "Epoch : [10/10][40/85] || LR : 0.00001 || Train Loss : 0.5983 (0.3663) || Train Top 1-acc : 100.000% (91.768)% || Train Top 5-acc : 100.000% (99.695)%\n",
      "Epoch : [10/10][50/85] || LR : 0.00001 || Train Loss : 0.8164 (0.3471) || Train Top 1-acc : 81.250% (91.544)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [10/10][60/85] || LR : 0.00001 || Train Loss : 0.2539 (0.3466) || Train Top 1-acc : 100.000% (91.496)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [10/10][70/85] || LR : 0.00001 || Train Loss : 0.0026 (0.3320) || Train Top 1-acc : 100.000% (91.637)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [10/10][80/85] || LR : 0.00001 || Train Loss : 0.3697 (0.3306) || Train Top 1-acc : 100.000% (91.821)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca0ddd5fb3848c2aec46566aa63f66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10] || Val Loss : 0.0249 || Val Top 1-acc : 99.115% || Val Top 5-acc : 100.000%\n",
      "\n",
      "\n",
      "'===============5-Fold Cross Validation==============='\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22f49b37c8147ed94a8a0aa807dd14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10][0/85] || LR : 0.00001 || Train Loss : 2.0386 (2.0386) || Train Top 1-acc : 6.250% (6.250)% || Train Top 5-acc : 75.000% (75.000)%\n",
      "Epoch : [1/10][10/85] || LR : 0.00003 || Train Loss : 2.0713 (1.9109) || Train Top 1-acc : 31.250% (20.455)% || Train Top 5-acc : 56.250% (79.545)%\n",
      "Epoch : [1/10][20/85] || LR : 0.00004 || Train Loss : 1.3254 (1.7304) || Train Top 1-acc : 75.000% (34.524)% || Train Top 5-acc : 100.000% (86.310)%\n",
      "Epoch : [1/10][30/85] || LR : 0.00006 || Train Loss : 1.0685 (1.5021) || Train Top 1-acc : 81.250% (46.169)% || Train Top 5-acc : 100.000% (90.524)%\n",
      "Epoch : [1/10][40/85] || LR : 0.00008 || Train Loss : 0.2387 (1.2839) || Train Top 1-acc : 93.750% (56.402)% || Train Top 5-acc : 100.000% (92.835)%\n",
      "Epoch : [1/10][50/85] || LR : 0.00009 || Train Loss : 1.2306 (1.1856) || Train Top 1-acc : 81.250% (61.520)% || Train Top 5-acc : 93.750% (93.995)%\n",
      "Epoch : [1/10][60/85] || LR : 0.00010 || Train Loss : 0.4093 (1.0717) || Train Top 1-acc : 93.750% (65.881)% || Train Top 5-acc : 100.000% (94.877)%\n",
      "Epoch : [1/10][70/85] || LR : 0.00010 || Train Loss : 0.9882 (1.0018) || Train Top 1-acc : 43.750% (68.134)% || Train Top 5-acc : 93.750% (95.511)%\n",
      "Epoch : [1/10][80/85] || LR : 0.00010 || Train Loss : 0.4428 (0.9365) || Train Top 1-acc : 93.750% (70.679)% || Train Top 5-acc : 100.000% (96.065)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0875f40cfcac4f6f881f51c4ed49f935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1/10] || Val Loss : 0.2146 || Val Top 1-acc : 94.690% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea503c7acf342378433c430a6e34a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10][0/85] || LR : 0.00010 || Train Loss : 0.0805 (0.0805) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [2/10][10/85] || LR : 0.00009 || Train Loss : 1.1480 (0.6476) || Train Top 1-acc : 50.000% (82.386)% || Train Top 5-acc : 100.000% (98.295)%\n",
      "Epoch : [2/10][20/85] || LR : 0.00009 || Train Loss : 0.1377 (0.5387) || Train Top 1-acc : 93.750% (86.310)% || Train Top 5-acc : 100.000% (98.810)%\n",
      "Epoch : [2/10][30/85] || LR : 0.00009 || Train Loss : 0.0670 (0.5262) || Train Top 1-acc : 100.000% (84.677)% || Train Top 5-acc : 100.000% (98.992)%\n",
      "Epoch : [2/10][40/85] || LR : 0.00008 || Train Loss : 0.2268 (0.5196) || Train Top 1-acc : 93.750% (84.756)% || Train Top 5-acc : 100.000% (99.238)%\n",
      "Epoch : [2/10][50/85] || LR : 0.00008 || Train Loss : 0.8585 (0.5349) || Train Top 1-acc : 81.250% (84.436)% || Train Top 5-acc : 100.000% (99.142)%\n",
      "Epoch : [2/10][60/85] || LR : 0.00007 || Train Loss : 0.5709 (0.5292) || Train Top 1-acc : 100.000% (85.143)% || Train Top 5-acc : 100.000% (99.078)%\n",
      "Epoch : [2/10][70/85] || LR : 0.00006 || Train Loss : 0.5153 (0.5029) || Train Top 1-acc : 93.750% (86.092)% || Train Top 5-acc : 100.000% (99.208)%\n",
      "Epoch : [2/10][80/85] || LR : 0.00006 || Train Loss : 0.9393 (0.4761) || Train Top 1-acc : 93.750% (87.423)% || Train Top 5-acc : 100.000% (99.306)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839f4dc84da5433798ab2eb669734c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2/10] || Val Loss : 0.1453 || Val Top 1-acc : 95.575% || Val Top 5-acc : 99.410%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc273b0cfec14b17af036e6c0aac9c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10][0/85] || LR : 0.00005 || Train Loss : 0.0124 (0.0124) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [3/10][10/85] || LR : 0.00005 || Train Loss : 0.0187 (0.2988) || Train Top 1-acc : 100.000% (87.500)% || Train Top 5-acc : 100.000% (99.432)%\n",
      "Epoch : [3/10][20/85] || LR : 0.00004 || Train Loss : 0.0271 (0.2670) || Train Top 1-acc : 100.000% (91.964)% || Train Top 5-acc : 100.000% (99.702)%\n",
      "Epoch : [3/10][30/85] || LR : 0.00004 || Train Loss : 0.0087 (0.2915) || Train Top 1-acc : 100.000% (89.718)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [3/10][40/85] || LR : 0.00003 || Train Loss : 0.0161 (0.2893) || Train Top 1-acc : 100.000% (90.549)% || Train Top 5-acc : 100.000% (99.695)%\n",
      "Epoch : [3/10][50/85] || LR : 0.00003 || Train Loss : 0.0083 (0.3079) || Train Top 1-acc : 100.000% (91.176)% || Train Top 5-acc : 100.000% (99.755)%\n",
      "Epoch : [3/10][60/85] || LR : 0.00002 || Train Loss : 0.0309 (0.3210) || Train Top 1-acc : 100.000% (92.008)% || Train Top 5-acc : 100.000% (99.795)%\n",
      "Epoch : [3/10][70/85] || LR : 0.00002 || Train Loss : 0.0124 (0.3300) || Train Top 1-acc : 100.000% (91.461)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [3/10][80/85] || LR : 0.00001 || Train Loss : 0.8605 (0.3338) || Train Top 1-acc : 75.000% (90.664)% || Train Top 5-acc : 100.000% (99.614)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e731a0b5eec149908a9054757ecad8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [3/10] || Val Loss : 0.1214 || Val Top 1-acc : 97.345% || Val Top 5-acc : 99.705%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fdc60307924cb888632546a7e093f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10][0/85] || LR : 0.00001 || Train Loss : 0.0080 (0.0080) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][10/85] || LR : 0.00001 || Train Loss : 0.0059 (0.2478) || Train Top 1-acc : 100.000% (92.614)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][20/85] || LR : 0.00001 || Train Loss : 0.9131 (0.2578) || Train Top 1-acc : 68.750% (91.964)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][30/85] || LR : 0.00001 || Train Loss : 0.7515 (0.2385) || Train Top 1-acc : 100.000% (94.153)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [4/10][40/85] || LR : 0.00002 || Train Loss : 0.4925 (0.2670) || Train Top 1-acc : 100.000% (93.750)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [4/10][50/85] || LR : 0.00003 || Train Loss : 0.0057 (0.2657) || Train Top 1-acc : 100.000% (94.240)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [4/10][60/85] || LR : 0.00003 || Train Loss : 0.3083 (0.2825) || Train Top 1-acc : 100.000% (93.135)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [4/10][70/85] || LR : 0.00004 || Train Loss : 0.0053 (0.2897) || Train Top 1-acc : 100.000% (91.285)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [4/10][80/85] || LR : 0.00005 || Train Loss : 0.0127 (0.2777) || Train Top 1-acc : 100.000% (91.435)% || Train Top 5-acc : 100.000% (99.846)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ec5bce17d04d768d6b3436a7a06d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [4/10] || Val Loss : 0.1148 || Val Top 1-acc : 96.755% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8267414fa94044b9b54cf4792d3d5754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10][0/85] || LR : 0.00005 || Train Loss : 0.6259 (0.6259) || Train Top 1-acc : 93.750% (93.750)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][10/85] || LR : 0.00005 || Train Loss : 0.7918 (0.2159) || Train Top 1-acc : 0.000% (89.773)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [5/10][20/85] || LR : 0.00005 || Train Loss : 0.7312 (0.3097) || Train Top 1-acc : 75.000% (86.607)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [5/10][30/85] || LR : 0.00005 || Train Loss : 0.2967 (0.2696) || Train Top 1-acc : 100.000% (89.113)% || Train Top 5-acc : 100.000% (99.597)%\n",
      "Epoch : [5/10][40/85] || LR : 0.00005 || Train Loss : 0.6948 (0.3178) || Train Top 1-acc : 62.500% (85.671)% || Train Top 5-acc : 100.000% (99.390)%\n",
      "Epoch : [5/10][50/85] || LR : 0.00005 || Train Loss : 0.0035 (0.3003) || Train Top 1-acc : 100.000% (87.868)% || Train Top 5-acc : 100.000% (99.510)%\n",
      "Epoch : [5/10][60/85] || LR : 0.00004 || Train Loss : 0.4196 (0.2807) || Train Top 1-acc : 93.750% (89.242)% || Train Top 5-acc : 100.000% (99.590)%\n",
      "Epoch : [5/10][70/85] || LR : 0.00004 || Train Loss : 0.6039 (0.2869) || Train Top 1-acc : 100.000% (89.613)% || Train Top 5-acc : 100.000% (99.648)%\n",
      "Epoch : [5/10][80/85] || LR : 0.00004 || Train Loss : 0.9320 (0.2970) || Train Top 1-acc : 81.250% (89.506)% || Train Top 5-acc : 100.000% (99.691)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182ea310ebdf4fdabe5d23de702f83e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [5/10] || Val Loss : 0.1448 || Val Top 1-acc : 95.870% || Val Top 5-acc : 99.705%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5714ca91f062408895606b344844b9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10][0/85] || LR : 0.00004 || Train Loss : 0.0042 (0.0042) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][10/85] || LR : 0.00003 || Train Loss : 0.3565 (0.2846) || Train Top 1-acc : 100.000% (95.455)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][20/85] || LR : 0.00003 || Train Loss : 0.0052 (0.2608) || Train Top 1-acc : 100.000% (95.238)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [6/10][30/85] || LR : 0.00003 || Train Loss : 0.6910 (0.2762) || Train Top 1-acc : 87.500% (91.129)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [6/10][40/85] || LR : 0.00003 || Train Loss : 0.6822 (0.2907) || Train Top 1-acc : 100.000% (92.988)% || Train Top 5-acc : 100.000% (99.848)%\n",
      "Epoch : [6/10][50/85] || LR : 0.00002 || Train Loss : 0.0330 (0.3036) || Train Top 1-acc : 100.000% (91.667)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [6/10][60/85] || LR : 0.00002 || Train Loss : 0.0039 (0.3174) || Train Top 1-acc : 100.000% (91.393)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [6/10][70/85] || LR : 0.00002 || Train Loss : 0.0062 (0.2918) || Train Top 1-acc : 100.000% (91.725)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [6/10][80/85] || LR : 0.00002 || Train Loss : 0.7268 (0.2846) || Train Top 1-acc : 43.750% (92.052)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeafab91ba14f24a5e90df283f490a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [6/10] || Val Loss : 0.1204 || Val Top 1-acc : 97.050% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae183dbad3ac400999dbfd32633e4f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10][0/85] || LR : 0.00002 || Train Loss : 0.0055 (0.0055) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [7/10][10/85] || LR : 0.00001 || Train Loss : 0.4340 (0.3952) || Train Top 1-acc : 50.000% (78.977)% || Train Top 5-acc : 100.000% (98.864)%\n",
      "Epoch : [7/10][20/85] || LR : 0.00001 || Train Loss : 0.0042 (0.3191) || Train Top 1-acc : 100.000% (82.440)% || Train Top 5-acc : 100.000% (99.405)%\n",
      "Epoch : [7/10][30/85] || LR : 0.00001 || Train Loss : 0.0018 (0.2937) || Train Top 1-acc : 100.000% (85.081)% || Train Top 5-acc : 100.000% (99.395)%\n",
      "Epoch : [7/10][40/85] || LR : 0.00001 || Train Loss : 0.7229 (0.2791) || Train Top 1-acc : 87.500% (87.500)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [7/10][50/85] || LR : 0.00001 || Train Loss : 0.6283 (0.3096) || Train Top 1-acc : 62.500% (87.868)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [7/10][60/85] || LR : 0.00001 || Train Loss : 0.0016 (0.3001) || Train Top 1-acc : 100.000% (89.139)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [7/10][70/85] || LR : 0.00001 || Train Loss : 0.2362 (0.2912) || Train Top 1-acc : 100.000% (88.556)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [7/10][80/85] || LR : 0.00002 || Train Loss : 0.0154 (0.2831) || Train Top 1-acc : 100.000% (88.812)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1700067b2b274777aab884189812da18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [7/10] || Val Loss : 0.1291 || Val Top 1-acc : 97.050% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8d67addfc444208f806a380ac38250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10][0/85] || LR : 0.00002 || Train Loss : 0.5337 (0.5337) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][10/85] || LR : 0.00002 || Train Loss : 0.0025 (0.1729) || Train Top 1-acc : 100.000% (96.591)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][20/85] || LR : 0.00002 || Train Loss : 0.0025 (0.1783) || Train Top 1-acc : 100.000% (94.643)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][30/85] || LR : 0.00002 || Train Loss : 0.0010 (0.1866) || Train Top 1-acc : 100.000% (95.363)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][40/85] || LR : 0.00002 || Train Loss : 0.5238 (0.2408) || Train Top 1-acc : 100.000% (94.360)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [8/10][50/85] || LR : 0.00002 || Train Loss : 0.5768 (0.2467) || Train Top 1-acc : 100.000% (93.505)% || Train Top 5-acc : 100.000% (99.877)%\n",
      "Epoch : [8/10][60/85] || LR : 0.00002 || Train Loss : 0.0017 (0.2528) || Train Top 1-acc : 100.000% (94.262)% || Train Top 5-acc : 100.000% (99.898)%\n",
      "Epoch : [8/10][70/85] || LR : 0.00002 || Train Loss : 0.0026 (0.2893) || Train Top 1-acc : 100.000% (92.958)% || Train Top 5-acc : 100.000% (99.912)%\n",
      "Epoch : [8/10][80/85] || LR : 0.00002 || Train Loss : 0.5362 (0.3126) || Train Top 1-acc : 100.000% (91.049)% || Train Top 5-acc : 100.000% (99.923)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f4288c45c443aaa14ccb7d4804bc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [8/10] || Val Loss : 0.1266 || Val Top 1-acc : 96.755% || Val Top 5-acc : 99.705%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd032d0c1fd84472be846abedabb3b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10][0/85] || LR : 0.00002 || Train Loss : 0.5063 (0.5063) || Train Top 1-acc : 100.000% (100.000)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][10/85] || LR : 0.00002 || Train Loss : 0.2515 (0.3973) || Train Top 1-acc : 100.000% (87.500)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][20/85] || LR : 0.00002 || Train Loss : 0.7745 (0.3355) || Train Top 1-acc : 100.000% (93.452)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [9/10][30/85] || LR : 0.00002 || Train Loss : 0.5575 (0.3380) || Train Top 1-acc : 93.750% (90.927)% || Train Top 5-acc : 100.000% (99.798)%\n",
      "Epoch : [9/10][40/85] || LR : 0.00002 || Train Loss : 0.0040 (0.3345) || Train Top 1-acc : 100.000% (89.177)% || Train Top 5-acc : 100.000% (99.543)%\n",
      "Epoch : [9/10][50/85] || LR : 0.00002 || Train Loss : 0.0038 (0.3008) || Train Top 1-acc : 100.000% (91.299)% || Train Top 5-acc : 100.000% (99.632)%\n",
      "Epoch : [9/10][60/85] || LR : 0.00002 || Train Loss : 0.5112 (0.2993) || Train Top 1-acc : 87.500% (92.316)% || Train Top 5-acc : 100.000% (99.693)%\n",
      "Epoch : [9/10][70/85] || LR : 0.00002 || Train Loss : 0.5287 (0.2962) || Train Top 1-acc : 100.000% (92.606)% || Train Top 5-acc : 100.000% (99.736)%\n",
      "Epoch : [9/10][80/85] || LR : 0.00001 || Train Loss : 0.6574 (0.3093) || Train Top 1-acc : 56.250% (92.130)% || Train Top 5-acc : 100.000% (99.769)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807e574834fe44ed86f90433eced5bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [9/10] || Val Loss : 0.1025 || Val Top 1-acc : 97.935% || Val Top 5-acc : 100.000%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a87d7443fa4e5a80798e0611f077a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10][0/85] || LR : 0.00001 || Train Loss : 0.7395 (0.7395) || Train Top 1-acc : 6.250% (6.250)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][10/85] || LR : 0.00001 || Train Loss : 0.0021 (0.3403) || Train Top 1-acc : 100.000% (86.932)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][20/85] || LR : 0.00001 || Train Loss : 0.0024 (0.2719) || Train Top 1-acc : 100.000% (88.393)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][30/85] || LR : 0.00001 || Train Loss : 0.0027 (0.2210) || Train Top 1-acc : 100.000% (91.734)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][40/85] || LR : 0.00001 || Train Loss : 0.0007 (0.2749) || Train Top 1-acc : 100.000% (88.872)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][50/85] || LR : 0.00001 || Train Loss : 0.0010 (0.2503) || Train Top 1-acc : 100.000% (90.074)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][60/85] || LR : 0.00001 || Train Loss : 0.4998 (0.2308) || Train Top 1-acc : 100.000% (90.471)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][70/85] || LR : 0.00001 || Train Loss : 0.0066 (0.2262) || Train Top 1-acc : 100.000% (91.813)% || Train Top 5-acc : 100.000% (100.000)%\n",
      "Epoch : [10/10][80/85] || LR : 0.00001 || Train Loss : 0.5944 (0.2119) || Train Top 1-acc : 87.500% (92.593)% || Train Top 5-acc : 100.000% (100.000)%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97552c7970643949b2c41c1d7ad94cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [10/10] || Val Loss : 0.1011 || Val Top 1-acc : 97.935% || Val Top 5-acc : 100.000%\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=cfg.values.train_args.n_splits)\n",
    "k = 1\n",
    "for train_idx, val_idx in kfold.split(whole_df, whole_label):\n",
    "    print('\\n')\n",
    "    cpprint('=' * 15 + f'{k}-Fold Cross Validation' + '=' * 15)\n",
    "    train_df = whole_df.iloc[train_idx]\n",
    "    val_df = whole_df.iloc[val_idx]\n",
    "\n",
    "    train_loader = get_dataloader(df=train_df, transform=train_transform, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    val_loader = get_dataloader(df=val_df, transform=val_transform, batch_size=VAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    train(cfg, k, train_loader, val_loader)\n",
    "\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "- Test Time Augmentation 사용 (only hflip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestDataset(Dataset):\n",
    "#     def __init__(self, data_path='./test/0/', transform=None):\n",
    "#         self.data_path = data_path\n",
    "#         self.data = os.listdir(data_path)\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):        \n",
    "#         image_path = os.path.join(self.data_path, self.data[idx])\n",
    "#         image = cv2.imread(image_path)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image=np.array(image))['image']\n",
    "            \n",
    "#         return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 77  \n",
    "# BATCH_SIZE = 32    \n",
    "# IMAGE_SIZE = 227\n",
    "# MODEL_ARC = 'nfnet_l0'\n",
    "# NUM_CLASSES = 7\n",
    "# MODEL_DIR = './results'\n",
    "# NUM_FOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fix random seed\n",
    "# def seed_everything(seed: int = 42):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)  # type: ignore\n",
    "#     torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "#     torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_transform = albumentations.Compose([               \n",
    "#         albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "#         albumentations.Normalize(mean=(0.4569, 0.5074, 0.5557), std=(0.2888, 0.2743, 0.2829)),\n",
    "#         albumentations.pytorch.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TestDataset(transform=test_transform)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PretrainedModel(nn.Module):\n",
    "#     def __init__(self, model_arc='swin_tiny_patch4_window7_224', num_classes=7):\n",
    "#         super().__init__()\n",
    "#         self.net = timm.create_model(model_arc, pretrained=False, num_classes=num_classes)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.net(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PretrainedModel(\n",
       "  (net): NormFreeNet(\n",
       "    (stem): Sequential(\n",
       "      (conv1): ScaledStdConv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act2): SiLU(inplace=True)\n",
       "      (conv2): ScaledStdConv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act3): SiLU(inplace=True)\n",
       "      (conv3): ScaledStdConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act4): SiLU(inplace=True)\n",
       "      (conv4): ScaledStdConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): NormFreeBlock(\n",
       "          (downsample): DownsampleAvg(\n",
       "            (pool): Identity()\n",
       "            (conv): ScaledStdConv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): NormFreeBlock(\n",
       "          (downsample): DownsampleAvg(\n",
       "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (conv): ScaledStdConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): NormFreeBlock(\n",
       "          (downsample): DownsampleAvg(\n",
       "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (conv): ScaledStdConv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(512, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (3): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (4): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (5): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): NormFreeBlock(\n",
       "          (downsample): DownsampleAvg(\n",
       "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "            (conv): ScaledStdConv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): NormFreeBlock(\n",
       "          (act1): SiLU()\n",
       "          (conv1): ScaledStdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act2): SiLU(inplace=True)\n",
       "          (conv2): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act2b): SiLU(inplace=True)\n",
       "          (conv2b): ScaledStdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6)\n",
       "          (act3): SiLU()\n",
       "          (conv3): ScaledStdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (attn_last): SEModule(\n",
       "            (fc1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): ReLU(inplace=True)\n",
       "            (fc2): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Sigmoid()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_conv): ScaledStdConv2d(1536, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_act): SiLU(inplace=True)\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "      (fc): Linear(in_features=2304, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = PretrainedModel(model_arc=MODEL_ARC, num_classes=NUM_CLASSES)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# states = [torch.load(glob(MODEL_DIR + f'/{MODEL_ARC}/{k}_fold/*.pth')[-1]) for k in range(1, NUM_FOLD + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transforms = tta.Compose(\n",
    "#     [\n",
    "#         tta.HorizontalFlip(),\n",
    "#         # tta.VerticalFlip(),\n",
    "#         # tta.Multiply(factors=[0.9, 1, 1.1])\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model ensemble을 위해서 npy 파일 형태로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7bdc42525840eab20120636e54f8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probs = []\n",
    "# save_ = []\n",
    "# for i, images in enumerate(tqdm(test_loader)):\n",
    "#     images = images.to(device)\n",
    "#     avg_preds = []\n",
    "#     for state in states:\n",
    "#         model.load_state_dict(state)\n",
    "#         model.eval()\n",
    "#         tta_model = tta.ClassificationTTAWrapper(model, transforms)\n",
    "#         tta_model.to(device)\n",
    "#         tta_model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             logits = tta_model(images)\n",
    "#         avg_preds.append(logits.to('cpu').numpy())\n",
    "#     avg_preds = np.mean(avg_preds, axis=0)\n",
    "#     save_.append(avg_preds)\n",
    "#     probs.append(avg_preds.argmax(-1))\n",
    "# save_ = np.concatenate(save_)\n",
    "# probs = np.concatenate(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./test_answer_sample_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(f'./{MODEL_ARC}.npy', save_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['answer value'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'submission_{MODEL_ARC}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "- nfnet_l0와 swin transformer 사용\n",
    "- stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy_list = [\n",
    "#     'nfnet_l0.npy',\n",
    "#     'swin_base_patch4_window7_224.npy'\n",
    "# ]\n",
    "\n",
    "# predictions = []\n",
    "# for f in npy_list:\n",
    "#     predictions.append(np.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 350, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final = np.array(predictions).mean(axis=0).argmax(-1)\n",
    "# final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./test_answer_sample_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['answer value'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f'submission_ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNHgfiaLWAfJXDLoBnx7ayu",
   "collapsed_sections": [],
   "name": "eda.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
